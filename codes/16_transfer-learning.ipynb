{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Dependencies"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 24,
   "metadata": {},
   "outputs": [],
   "source": [
    "import numpy as np\n",
    "import matplotlib.pyplot as plt\n",
    "\n",
    "import torch\n",
    "from torch import nn\n",
    "from torch.optim import Adam\n",
    "from torch.utils.data import DataLoader\n",
    "\n",
    "from torchvision.models import resnet50, ResNet50_Weights\n",
    "from torchvision.transforms import v2\n",
    "from torchvision.datasets import CIFAR10\n",
    "\n",
    "from torchsummary import summary\n",
    "\n",
    "from torchmetrics import Accuracy"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 25,
   "metadata": {},
   "outputs": [],
   "source": [
    "# set a fixed seed\n",
    "random_state = 42\n",
    "torch.manual_seed(random_state)\n",
    "torch.cuda.manual_seed(random_state)\n",
    "np.random.seed(random_state)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 26,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "device(type='cuda')"
      ]
     },
     "execution_count": 26,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "device = torch.device('cuda' if torch.cuda.is_available() else 'cpu')\n",
    "device"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Pre-Processing"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Load Dataset"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 27,
   "metadata": {},
   "outputs": [],
   "source": [
    "# initial transforms\n",
    "transforms = v2.Compose(\n",
    "    [\n",
    "        v2.ToImage(),\n",
    "        v2.ToDtype(torch.float32, scale= True)\n",
    "    ]\n",
    ")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 28,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Files already downloaded and verified\n",
      "Files already downloaded and verified\n",
      "trainset:\n",
      "    -> trainset.data.shape    : (50000, 32, 32, 3)\n",
      "    -> trainset.data.dtype    : uint8\n",
      "    -> type(trainset.data)    : <class 'numpy.ndarray'>\n",
      "    -> type(trainset.targets) : <class 'list'>\n",
      "--------------------------------------------------\n",
      "testset:\n",
      "    -> testset.data.shape     : (10000, 32, 32, 3)\n",
      "    -> testset.data.dtype     : uint8\n",
      "    -> type(testset.data)     : <class 'numpy.ndarray'>\n",
      "    -> type(testset.targets)  : <class 'list'>\n",
      "--------------------------------------------------\n",
      "classes: ['airplane', 'automobile', 'bird', 'cat', 'deer', 'dog', 'frog', 'horse', 'ship', 'truck']\n",
      "trainset distribution: [5000 5000 5000 5000 5000 5000 5000 5000 5000 5000]\n",
      "testset  distribution: [1000 1000 1000 1000 1000 1000 1000 1000 1000 1000]\n"
     ]
    }
   ],
   "source": [
    "trainset = CIFAR10(root= './dataset', train= True , transform= transforms, download= True)\n",
    "testset  = CIFAR10(root= './dataset', train= False, transform= transforms, download= True)\n",
    "\n",
    "# log\n",
    "print('trainset:')\n",
    "print(f\"    -> trainset.data.shape    : {trainset.data.shape}\")\n",
    "print(f\"    -> trainset.data.dtype    : {trainset.data.dtype}\")\n",
    "print(f\"    -> type(trainset.data)    : {type(trainset.data)}\")\n",
    "print(f\"    -> type(trainset.targets) : {type(trainset.targets)}\")\n",
    "print('-' * 50)\n",
    "print('testset:')\n",
    "print(f\"    -> testset.data.shape     : {testset.data.shape}\")\n",
    "print(f\"    -> testset.data.dtype     : {testset.data.dtype}\")\n",
    "print(f\"    -> type(testset.data)     : {type(testset.data)}\")\n",
    "print(f\"    -> type(testset.targets)  : {type(testset.targets)}\")\n",
    "print('-' * 50)\n",
    "print(f\"classes: {trainset.classes}\")\n",
    "print(f\"trainset distribution: {np.unique(trainset.targets, return_counts= True)[1]}\")\n",
    "print(f\"testset  distribution: {np.unique(testset.targets, return_counts= True)[1]}\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# plot\n",
    "fig, axs = plt.subplots(nrows= 4, ncols= 8, figsize= (12, 6), layout= 'compressed')\n",
    "for i in range(4):\n",
    "    for j in range(8):\n",
    "        axs[i, j].imshow(trainset.data[i * 8 + j], cmap= 'gray')\n",
    "        axs[i, j].set_title(trainset.classes[trainset.targets[i * 8 + j]])\n",
    "        axs[i, j].axis('off')\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Normalization"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 30,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "train mean per channel: tensor([0.4914, 0.4822, 0.4465])\n",
      "train std  per channel: tensor([0.2470, 0.2435, 0.2616])\n"
     ]
    }
   ],
   "source": [
    "data = next(iter(DataLoader(trainset, batch_size= len(trainset))))[0]\n",
    "\n",
    "train_mean = data.mean(axis= (0, 2, 3))\n",
    "train_std  = data.std(axis= (0, 2, 3))\n",
    "\n",
    "del data\n",
    "\n",
    "# log\n",
    "print(f\"train mean per channel: {train_mean}\")\n",
    "print(f\"train std  per channel: {train_std}\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 31,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "StandardTransform\n",
      "Transform: Compose(\n",
      "                 ToImage()\n",
      "                 ToDtype(scale=True)\n",
      "                 Normalize(mean=[tensor(0.4914), tensor(0.4822), tensor(0.4465)], std=[tensor(0.2470), tensor(0.2435), tensor(0.2616)], inplace=False)\n",
      "           )\n",
      "StandardTransform\n",
      "Transform: Compose(\n",
      "                 ToImage()\n",
      "                 ToDtype(scale=True)\n",
      "                 Normalize(mean=[tensor(0.4914), tensor(0.4822), tensor(0.4465)], std=[tensor(0.2470), tensor(0.2435), tensor(0.2616)], inplace=False)\n",
      "           )\n"
     ]
    }
   ],
   "source": [
    "transforms.transforms.append(v2.Normalize(mean= train_mean, std= train_std))\n",
    "\n",
    "# log\n",
    "print(trainset.transforms)\n",
    "print(testset.transforms)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 32,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "before applying transform:\n",
      "    -> type(testset.data[0]) : <class 'numpy.ndarray'>\n",
      "    -> testset.data[0].dtype : uint8\n",
      "    -> testset.data[0].shape : (32, 32, 3)\n",
      "--------------------------------------------------\n",
      "after applying transform:\n",
      "    -> type(testset[0][0])   : <class 'torchvision.tv_tensors._image.Image'>\n",
      "    -> testset[0][0].dtype   : torch.float32\n",
      "    -> testset[0][0].shape   : torch.Size([3, 32, 32])\n"
     ]
    }
   ],
   "source": [
    "# log\n",
    "print(\"before applying transform:\")\n",
    "print(f\"    -> type(testset.data[0]) : {type(testset.data[0])}\")\n",
    "print(f\"    -> testset.data[0].dtype : {testset.data[0].dtype}\")\n",
    "print(f\"    -> testset.data[0].shape : {testset.data[0].shape}\")\n",
    "print('-' * 50)\n",
    "print(\"after applying transform:\")\n",
    "print(f\"    -> type(testset[0][0])   : {type(testset[0][0])}\")\n",
    "print(f\"    -> testset[0][0].dtype   : {testset[0][0].dtype}\")\n",
    "print(f\"    -> testset[0][0].shape   : {testset[0][0].shape}\")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## DataLoader"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 33,
   "metadata": {},
   "outputs": [],
   "source": [
    "batch_size = 64\n",
    "trainloader = DataLoader(trainset, batch_size= batch_size, shuffle= True, num_workers= 2)\n",
    "testloader  = DataLoader(testset, batch_size= batch_size, shuffle= False, num_workers= 2)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Transfer Learning\n",
    "   - resnet50 pretrained on IMAGENET1K_V1"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 34,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "ResNet(\n",
      "  (conv1): Conv2d(3, 64, kernel_size=(7, 7), stride=(2, 2), padding=(3, 3), bias=False)\n",
      "  (bn1): BatchNorm2d(64, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
      "  (relu): ReLU(inplace=True)\n",
      "  (maxpool): MaxPool2d(kernel_size=3, stride=2, padding=1, dilation=1, ceil_mode=False)\n",
      "  (layer1): Sequential(\n",
      "    (0): Bottleneck(\n",
      "      (conv1): Conv2d(64, 64, kernel_size=(1, 1), stride=(1, 1), bias=False)\n",
      "      (bn1): BatchNorm2d(64, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
      "      (conv2): Conv2d(64, 64, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), bias=False)\n",
      "      (bn2): BatchNorm2d(64, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
      "      (conv3): Conv2d(64, 256, kernel_size=(1, 1), stride=(1, 1), bias=False)\n",
      "      (bn3): BatchNorm2d(256, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
      "      (relu): ReLU(inplace=True)\n",
      "      (downsample): Sequential(\n",
      "        (0): Conv2d(64, 256, kernel_size=(1, 1), stride=(1, 1), bias=False)\n",
      "        (1): BatchNorm2d(256, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
      "      )\n",
      "    )\n",
      "    (1): Bottleneck(\n",
      "      (conv1): Conv2d(256, 64, kernel_size=(1, 1), stride=(1, 1), bias=False)\n",
      "      (bn1): BatchNorm2d(64, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
      "      (conv2): Conv2d(64, 64, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), bias=False)\n",
      "      (bn2): BatchNorm2d(64, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
      "      (conv3): Conv2d(64, 256, kernel_size=(1, 1), stride=(1, 1), bias=False)\n",
      "      (bn3): BatchNorm2d(256, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
      "      (relu): ReLU(inplace=True)\n",
      "    )\n",
      "    (2): Bottleneck(\n",
      "      (conv1): Conv2d(256, 64, kernel_size=(1, 1), stride=(1, 1), bias=False)\n",
      "      (bn1): BatchNorm2d(64, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
      "      (conv2): Conv2d(64, 64, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), bias=False)\n",
      "      (bn2): BatchNorm2d(64, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
      "      (conv3): Conv2d(64, 256, kernel_size=(1, 1), stride=(1, 1), bias=False)\n",
      "      (bn3): BatchNorm2d(256, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
      "      (relu): ReLU(inplace=True)\n",
      "    )\n",
      "  )\n",
      "  (layer2): Sequential(\n",
      "    (0): Bottleneck(\n",
      "      (conv1): Conv2d(256, 128, kernel_size=(1, 1), stride=(1, 1), bias=False)\n",
      "      (bn1): BatchNorm2d(128, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
      "      (conv2): Conv2d(128, 128, kernel_size=(3, 3), stride=(2, 2), padding=(1, 1), bias=False)\n",
      "      (bn2): BatchNorm2d(128, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
      "      (conv3): Conv2d(128, 512, kernel_size=(1, 1), stride=(1, 1), bias=False)\n",
      "      (bn3): BatchNorm2d(512, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
      "      (relu): ReLU(inplace=True)\n",
      "      (downsample): Sequential(\n",
      "        (0): Conv2d(256, 512, kernel_size=(1, 1), stride=(2, 2), bias=False)\n",
      "        (1): BatchNorm2d(512, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
      "      )\n",
      "    )\n",
      "    (1): Bottleneck(\n",
      "      (conv1): Conv2d(512, 128, kernel_size=(1, 1), stride=(1, 1), bias=False)\n",
      "      (bn1): BatchNorm2d(128, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
      "      (conv2): Conv2d(128, 128, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), bias=False)\n",
      "      (bn2): BatchNorm2d(128, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
      "      (conv3): Conv2d(128, 512, kernel_size=(1, 1), stride=(1, 1), bias=False)\n",
      "      (bn3): BatchNorm2d(512, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
      "      (relu): ReLU(inplace=True)\n",
      "    )\n",
      "    (2): Bottleneck(\n",
      "      (conv1): Conv2d(512, 128, kernel_size=(1, 1), stride=(1, 1), bias=False)\n",
      "      (bn1): BatchNorm2d(128, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
      "      (conv2): Conv2d(128, 128, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), bias=False)\n",
      "      (bn2): BatchNorm2d(128, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
      "      (conv3): Conv2d(128, 512, kernel_size=(1, 1), stride=(1, 1), bias=False)\n",
      "      (bn3): BatchNorm2d(512, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
      "      (relu): ReLU(inplace=True)\n",
      "    )\n",
      "    (3): Bottleneck(\n",
      "      (conv1): Conv2d(512, 128, kernel_size=(1, 1), stride=(1, 1), bias=False)\n",
      "      (bn1): BatchNorm2d(128, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
      "      (conv2): Conv2d(128, 128, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), bias=False)\n",
      "      (bn2): BatchNorm2d(128, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
      "      (conv3): Conv2d(128, 512, kernel_size=(1, 1), stride=(1, 1), bias=False)\n",
      "      (bn3): BatchNorm2d(512, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
      "      (relu): ReLU(inplace=True)\n",
      "    )\n",
      "  )\n",
      "  (layer3): Sequential(\n",
      "    (0): Bottleneck(\n",
      "      (conv1): Conv2d(512, 256, kernel_size=(1, 1), stride=(1, 1), bias=False)\n",
      "      (bn1): BatchNorm2d(256, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
      "      (conv2): Conv2d(256, 256, kernel_size=(3, 3), stride=(2, 2), padding=(1, 1), bias=False)\n",
      "      (bn2): BatchNorm2d(256, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
      "      (conv3): Conv2d(256, 1024, kernel_size=(1, 1), stride=(1, 1), bias=False)\n",
      "      (bn3): BatchNorm2d(1024, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
      "      (relu): ReLU(inplace=True)\n",
      "      (downsample): Sequential(\n",
      "        (0): Conv2d(512, 1024, kernel_size=(1, 1), stride=(2, 2), bias=False)\n",
      "        (1): BatchNorm2d(1024, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
      "      )\n",
      "    )\n",
      "    (1): Bottleneck(\n",
      "      (conv1): Conv2d(1024, 256, kernel_size=(1, 1), stride=(1, 1), bias=False)\n",
      "      (bn1): BatchNorm2d(256, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
      "      (conv2): Conv2d(256, 256, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), bias=False)\n",
      "      (bn2): BatchNorm2d(256, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
      "      (conv3): Conv2d(256, 1024, kernel_size=(1, 1), stride=(1, 1), bias=False)\n",
      "      (bn3): BatchNorm2d(1024, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
      "      (relu): ReLU(inplace=True)\n",
      "    )\n",
      "    (2): Bottleneck(\n",
      "      (conv1): Conv2d(1024, 256, kernel_size=(1, 1), stride=(1, 1), bias=False)\n",
      "      (bn1): BatchNorm2d(256, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
      "      (conv2): Conv2d(256, 256, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), bias=False)\n",
      "      (bn2): BatchNorm2d(256, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
      "      (conv3): Conv2d(256, 1024, kernel_size=(1, 1), stride=(1, 1), bias=False)\n",
      "      (bn3): BatchNorm2d(1024, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
      "      (relu): ReLU(inplace=True)\n",
      "    )\n",
      "    (3): Bottleneck(\n",
      "      (conv1): Conv2d(1024, 256, kernel_size=(1, 1), stride=(1, 1), bias=False)\n",
      "      (bn1): BatchNorm2d(256, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
      "      (conv2): Conv2d(256, 256, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), bias=False)\n",
      "      (bn2): BatchNorm2d(256, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
      "      (conv3): Conv2d(256, 1024, kernel_size=(1, 1), stride=(1, 1), bias=False)\n",
      "      (bn3): BatchNorm2d(1024, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
      "      (relu): ReLU(inplace=True)\n",
      "    )\n",
      "    (4): Bottleneck(\n",
      "      (conv1): Conv2d(1024, 256, kernel_size=(1, 1), stride=(1, 1), bias=False)\n",
      "      (bn1): BatchNorm2d(256, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
      "      (conv2): Conv2d(256, 256, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), bias=False)\n",
      "      (bn2): BatchNorm2d(256, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
      "      (conv3): Conv2d(256, 1024, kernel_size=(1, 1), stride=(1, 1), bias=False)\n",
      "      (bn3): BatchNorm2d(1024, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
      "      (relu): ReLU(inplace=True)\n",
      "    )\n",
      "    (5): Bottleneck(\n",
      "      (conv1): Conv2d(1024, 256, kernel_size=(1, 1), stride=(1, 1), bias=False)\n",
      "      (bn1): BatchNorm2d(256, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
      "      (conv2): Conv2d(256, 256, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), bias=False)\n",
      "      (bn2): BatchNorm2d(256, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
      "      (conv3): Conv2d(256, 1024, kernel_size=(1, 1), stride=(1, 1), bias=False)\n",
      "      (bn3): BatchNorm2d(1024, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
      "      (relu): ReLU(inplace=True)\n",
      "    )\n",
      "  )\n",
      "  (layer4): Sequential(\n",
      "    (0): Bottleneck(\n",
      "      (conv1): Conv2d(1024, 512, kernel_size=(1, 1), stride=(1, 1), bias=False)\n",
      "      (bn1): BatchNorm2d(512, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
      "      (conv2): Conv2d(512, 512, kernel_size=(3, 3), stride=(2, 2), padding=(1, 1), bias=False)\n",
      "      (bn2): BatchNorm2d(512, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
      "      (conv3): Conv2d(512, 2048, kernel_size=(1, 1), stride=(1, 1), bias=False)\n",
      "      (bn3): BatchNorm2d(2048, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
      "      (relu): ReLU(inplace=True)\n",
      "      (downsample): Sequential(\n",
      "        (0): Conv2d(1024, 2048, kernel_size=(1, 1), stride=(2, 2), bias=False)\n",
      "        (1): BatchNorm2d(2048, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
      "      )\n",
      "    )\n",
      "    (1): Bottleneck(\n",
      "      (conv1): Conv2d(2048, 512, kernel_size=(1, 1), stride=(1, 1), bias=False)\n",
      "      (bn1): BatchNorm2d(512, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
      "      (conv2): Conv2d(512, 512, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), bias=False)\n",
      "      (bn2): BatchNorm2d(512, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
      "      (conv3): Conv2d(512, 2048, kernel_size=(1, 1), stride=(1, 1), bias=False)\n",
      "      (bn3): BatchNorm2d(2048, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
      "      (relu): ReLU(inplace=True)\n",
      "    )\n",
      "    (2): Bottleneck(\n",
      "      (conv1): Conv2d(2048, 512, kernel_size=(1, 1), stride=(1, 1), bias=False)\n",
      "      (bn1): BatchNorm2d(512, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
      "      (conv2): Conv2d(512, 512, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), bias=False)\n",
      "      (bn2): BatchNorm2d(512, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
      "      (conv3): Conv2d(512, 2048, kernel_size=(1, 1), stride=(1, 1), bias=False)\n",
      "      (bn3): BatchNorm2d(2048, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
      "      (relu): ReLU(inplace=True)\n",
      "    )\n",
      "  )\n",
      "  (avgpool): AdaptiveAvgPool2d(output_size=(1, 1))\n",
      "  (fc): Linear(in_features=2048, out_features=1000, bias=True)\n",
      ")\n"
     ]
    }
   ],
   "source": [
    "resnet = resnet50(weights= ResNet50_Weights.IMAGENET1K_V1)\n",
    "\n",
    "# log\n",
    "print(resnet)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 35,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "----------------------------------------------------------------\n",
      "        Layer (type)               Output Shape         Param #\n",
      "================================================================\n",
      "            Conv2d-1           [-1, 64, 16, 16]           9,408\n",
      "       BatchNorm2d-2           [-1, 64, 16, 16]             128\n",
      "              ReLU-3           [-1, 64, 16, 16]               0\n",
      "         MaxPool2d-4             [-1, 64, 8, 8]               0\n",
      "            Conv2d-5             [-1, 64, 8, 8]           4,096\n",
      "       BatchNorm2d-6             [-1, 64, 8, 8]             128\n",
      "              ReLU-7             [-1, 64, 8, 8]               0\n",
      "            Conv2d-8             [-1, 64, 8, 8]          36,864\n",
      "       BatchNorm2d-9             [-1, 64, 8, 8]             128\n",
      "             ReLU-10             [-1, 64, 8, 8]               0\n",
      "           Conv2d-11            [-1, 256, 8, 8]          16,384\n",
      "      BatchNorm2d-12            [-1, 256, 8, 8]             512\n",
      "           Conv2d-13            [-1, 256, 8, 8]          16,384\n",
      "      BatchNorm2d-14            [-1, 256, 8, 8]             512\n",
      "             ReLU-15            [-1, 256, 8, 8]               0\n",
      "       Bottleneck-16            [-1, 256, 8, 8]               0\n",
      "           Conv2d-17             [-1, 64, 8, 8]          16,384\n",
      "      BatchNorm2d-18             [-1, 64, 8, 8]             128\n",
      "             ReLU-19             [-1, 64, 8, 8]               0\n",
      "           Conv2d-20             [-1, 64, 8, 8]          36,864\n",
      "      BatchNorm2d-21             [-1, 64, 8, 8]             128\n",
      "             ReLU-22             [-1, 64, 8, 8]               0\n",
      "           Conv2d-23            [-1, 256, 8, 8]          16,384\n",
      "      BatchNorm2d-24            [-1, 256, 8, 8]             512\n",
      "             ReLU-25            [-1, 256, 8, 8]               0\n",
      "       Bottleneck-26            [-1, 256, 8, 8]               0\n",
      "           Conv2d-27             [-1, 64, 8, 8]          16,384\n",
      "      BatchNorm2d-28             [-1, 64, 8, 8]             128\n",
      "             ReLU-29             [-1, 64, 8, 8]               0\n",
      "           Conv2d-30             [-1, 64, 8, 8]          36,864\n",
      "      BatchNorm2d-31             [-1, 64, 8, 8]             128\n",
      "             ReLU-32             [-1, 64, 8, 8]               0\n",
      "           Conv2d-33            [-1, 256, 8, 8]          16,384\n",
      "      BatchNorm2d-34            [-1, 256, 8, 8]             512\n",
      "             ReLU-35            [-1, 256, 8, 8]               0\n",
      "       Bottleneck-36            [-1, 256, 8, 8]               0\n",
      "           Conv2d-37            [-1, 128, 8, 8]          32,768\n",
      "      BatchNorm2d-38            [-1, 128, 8, 8]             256\n",
      "             ReLU-39            [-1, 128, 8, 8]               0\n",
      "           Conv2d-40            [-1, 128, 4, 4]         147,456\n",
      "      BatchNorm2d-41            [-1, 128, 4, 4]             256\n",
      "             ReLU-42            [-1, 128, 4, 4]               0\n",
      "           Conv2d-43            [-1, 512, 4, 4]          65,536\n",
      "      BatchNorm2d-44            [-1, 512, 4, 4]           1,024\n",
      "           Conv2d-45            [-1, 512, 4, 4]         131,072\n",
      "      BatchNorm2d-46            [-1, 512, 4, 4]           1,024\n",
      "             ReLU-47            [-1, 512, 4, 4]               0\n",
      "       Bottleneck-48            [-1, 512, 4, 4]               0\n",
      "           Conv2d-49            [-1, 128, 4, 4]          65,536\n",
      "      BatchNorm2d-50            [-1, 128, 4, 4]             256\n",
      "             ReLU-51            [-1, 128, 4, 4]               0\n",
      "           Conv2d-52            [-1, 128, 4, 4]         147,456\n",
      "      BatchNorm2d-53            [-1, 128, 4, 4]             256\n",
      "             ReLU-54            [-1, 128, 4, 4]               0\n",
      "           Conv2d-55            [-1, 512, 4, 4]          65,536\n",
      "      BatchNorm2d-56            [-1, 512, 4, 4]           1,024\n",
      "             ReLU-57            [-1, 512, 4, 4]               0\n",
      "       Bottleneck-58            [-1, 512, 4, 4]               0\n",
      "           Conv2d-59            [-1, 128, 4, 4]          65,536\n",
      "      BatchNorm2d-60            [-1, 128, 4, 4]             256\n",
      "             ReLU-61            [-1, 128, 4, 4]               0\n",
      "           Conv2d-62            [-1, 128, 4, 4]         147,456\n",
      "      BatchNorm2d-63            [-1, 128, 4, 4]             256\n",
      "             ReLU-64            [-1, 128, 4, 4]               0\n",
      "           Conv2d-65            [-1, 512, 4, 4]          65,536\n",
      "      BatchNorm2d-66            [-1, 512, 4, 4]           1,024\n",
      "             ReLU-67            [-1, 512, 4, 4]               0\n",
      "       Bottleneck-68            [-1, 512, 4, 4]               0\n",
      "           Conv2d-69            [-1, 128, 4, 4]          65,536\n",
      "      BatchNorm2d-70            [-1, 128, 4, 4]             256\n",
      "             ReLU-71            [-1, 128, 4, 4]               0\n",
      "           Conv2d-72            [-1, 128, 4, 4]         147,456\n",
      "      BatchNorm2d-73            [-1, 128, 4, 4]             256\n",
      "             ReLU-74            [-1, 128, 4, 4]               0\n",
      "           Conv2d-75            [-1, 512, 4, 4]          65,536\n",
      "      BatchNorm2d-76            [-1, 512, 4, 4]           1,024\n",
      "             ReLU-77            [-1, 512, 4, 4]               0\n",
      "       Bottleneck-78            [-1, 512, 4, 4]               0\n",
      "           Conv2d-79            [-1, 256, 4, 4]         131,072\n",
      "      BatchNorm2d-80            [-1, 256, 4, 4]             512\n",
      "             ReLU-81            [-1, 256, 4, 4]               0\n",
      "           Conv2d-82            [-1, 256, 2, 2]         589,824\n",
      "      BatchNorm2d-83            [-1, 256, 2, 2]             512\n",
      "             ReLU-84            [-1, 256, 2, 2]               0\n",
      "           Conv2d-85           [-1, 1024, 2, 2]         262,144\n",
      "      BatchNorm2d-86           [-1, 1024, 2, 2]           2,048\n",
      "           Conv2d-87           [-1, 1024, 2, 2]         524,288\n",
      "      BatchNorm2d-88           [-1, 1024, 2, 2]           2,048\n",
      "             ReLU-89           [-1, 1024, 2, 2]               0\n",
      "       Bottleneck-90           [-1, 1024, 2, 2]               0\n",
      "           Conv2d-91            [-1, 256, 2, 2]         262,144\n",
      "      BatchNorm2d-92            [-1, 256, 2, 2]             512\n",
      "             ReLU-93            [-1, 256, 2, 2]               0\n",
      "           Conv2d-94            [-1, 256, 2, 2]         589,824\n",
      "      BatchNorm2d-95            [-1, 256, 2, 2]             512\n",
      "             ReLU-96            [-1, 256, 2, 2]               0\n",
      "           Conv2d-97           [-1, 1024, 2, 2]         262,144\n",
      "      BatchNorm2d-98           [-1, 1024, 2, 2]           2,048\n",
      "             ReLU-99           [-1, 1024, 2, 2]               0\n",
      "      Bottleneck-100           [-1, 1024, 2, 2]               0\n",
      "          Conv2d-101            [-1, 256, 2, 2]         262,144\n",
      "     BatchNorm2d-102            [-1, 256, 2, 2]             512\n",
      "            ReLU-103            [-1, 256, 2, 2]               0\n",
      "          Conv2d-104            [-1, 256, 2, 2]         589,824\n",
      "     BatchNorm2d-105            [-1, 256, 2, 2]             512\n",
      "            ReLU-106            [-1, 256, 2, 2]               0\n",
      "          Conv2d-107           [-1, 1024, 2, 2]         262,144\n",
      "     BatchNorm2d-108           [-1, 1024, 2, 2]           2,048\n",
      "            ReLU-109           [-1, 1024, 2, 2]               0\n",
      "      Bottleneck-110           [-1, 1024, 2, 2]               0\n",
      "          Conv2d-111            [-1, 256, 2, 2]         262,144\n",
      "     BatchNorm2d-112            [-1, 256, 2, 2]             512\n",
      "            ReLU-113            [-1, 256, 2, 2]               0\n",
      "          Conv2d-114            [-1, 256, 2, 2]         589,824\n",
      "     BatchNorm2d-115            [-1, 256, 2, 2]             512\n",
      "            ReLU-116            [-1, 256, 2, 2]               0\n",
      "          Conv2d-117           [-1, 1024, 2, 2]         262,144\n",
      "     BatchNorm2d-118           [-1, 1024, 2, 2]           2,048\n",
      "            ReLU-119           [-1, 1024, 2, 2]               0\n",
      "      Bottleneck-120           [-1, 1024, 2, 2]               0\n",
      "          Conv2d-121            [-1, 256, 2, 2]         262,144\n",
      "     BatchNorm2d-122            [-1, 256, 2, 2]             512\n",
      "            ReLU-123            [-1, 256, 2, 2]               0\n",
      "          Conv2d-124            [-1, 256, 2, 2]         589,824\n",
      "     BatchNorm2d-125            [-1, 256, 2, 2]             512\n",
      "            ReLU-126            [-1, 256, 2, 2]               0\n",
      "          Conv2d-127           [-1, 1024, 2, 2]         262,144\n",
      "     BatchNorm2d-128           [-1, 1024, 2, 2]           2,048\n",
      "            ReLU-129           [-1, 1024, 2, 2]               0\n",
      "      Bottleneck-130           [-1, 1024, 2, 2]               0\n",
      "          Conv2d-131            [-1, 256, 2, 2]         262,144\n",
      "     BatchNorm2d-132            [-1, 256, 2, 2]             512\n",
      "            ReLU-133            [-1, 256, 2, 2]               0\n",
      "          Conv2d-134            [-1, 256, 2, 2]         589,824\n",
      "     BatchNorm2d-135            [-1, 256, 2, 2]             512\n",
      "            ReLU-136            [-1, 256, 2, 2]               0\n",
      "          Conv2d-137           [-1, 1024, 2, 2]         262,144\n",
      "     BatchNorm2d-138           [-1, 1024, 2, 2]           2,048\n",
      "            ReLU-139           [-1, 1024, 2, 2]               0\n",
      "      Bottleneck-140           [-1, 1024, 2, 2]               0\n",
      "          Conv2d-141            [-1, 512, 2, 2]         524,288\n",
      "     BatchNorm2d-142            [-1, 512, 2, 2]           1,024\n",
      "            ReLU-143            [-1, 512, 2, 2]               0\n",
      "          Conv2d-144            [-1, 512, 1, 1]       2,359,296\n",
      "     BatchNorm2d-145            [-1, 512, 1, 1]           1,024\n",
      "            ReLU-146            [-1, 512, 1, 1]               0\n",
      "          Conv2d-147           [-1, 2048, 1, 1]       1,048,576\n",
      "     BatchNorm2d-148           [-1, 2048, 1, 1]           4,096\n",
      "          Conv2d-149           [-1, 2048, 1, 1]       2,097,152\n",
      "     BatchNorm2d-150           [-1, 2048, 1, 1]           4,096\n",
      "            ReLU-151           [-1, 2048, 1, 1]               0\n",
      "      Bottleneck-152           [-1, 2048, 1, 1]               0\n",
      "          Conv2d-153            [-1, 512, 1, 1]       1,048,576\n",
      "     BatchNorm2d-154            [-1, 512, 1, 1]           1,024\n",
      "            ReLU-155            [-1, 512, 1, 1]               0\n",
      "          Conv2d-156            [-1, 512, 1, 1]       2,359,296\n",
      "     BatchNorm2d-157            [-1, 512, 1, 1]           1,024\n",
      "            ReLU-158            [-1, 512, 1, 1]               0\n",
      "          Conv2d-159           [-1, 2048, 1, 1]       1,048,576\n",
      "     BatchNorm2d-160           [-1, 2048, 1, 1]           4,096\n",
      "            ReLU-161           [-1, 2048, 1, 1]               0\n",
      "      Bottleneck-162           [-1, 2048, 1, 1]               0\n",
      "          Conv2d-163            [-1, 512, 1, 1]       1,048,576\n",
      "     BatchNorm2d-164            [-1, 512, 1, 1]           1,024\n",
      "            ReLU-165            [-1, 512, 1, 1]               0\n",
      "          Conv2d-166            [-1, 512, 1, 1]       2,359,296\n",
      "     BatchNorm2d-167            [-1, 512, 1, 1]           1,024\n",
      "            ReLU-168            [-1, 512, 1, 1]               0\n",
      "          Conv2d-169           [-1, 2048, 1, 1]       1,048,576\n",
      "     BatchNorm2d-170           [-1, 2048, 1, 1]           4,096\n",
      "            ReLU-171           [-1, 2048, 1, 1]               0\n",
      "      Bottleneck-172           [-1, 2048, 1, 1]               0\n",
      "AdaptiveAvgPool2d-173           [-1, 2048, 1, 1]               0\n",
      "          Linear-174                 [-1, 1000]       2,049,000\n",
      "================================================================\n",
      "Total params: 25,557,032\n",
      "Trainable params: 25,557,032\n",
      "Non-trainable params: 0\n",
      "----------------------------------------------------------------\n",
      "Input size (MB): 0.01\n",
      "Forward/backward pass size (MB): 5.87\n",
      "Params size (MB): 97.49\n",
      "Estimated Total Size (MB): 103.37\n",
      "----------------------------------------------------------------\n"
     ]
    }
   ],
   "source": [
    "summary(resnet, trainset[0][0].shape, device= 'cpu')"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Extract a subset of Pretrained Model"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 36,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "0.weight                - requires_grad: True\n",
      "1.weight                - requires_grad: True\n",
      "1.bias                  - requires_grad: True\n",
      "4.0.conv1.weight        - requires_grad: True\n",
      "4.0.bn1.weight          - requires_grad: True\n",
      "4.0.bn1.bias            - requires_grad: True\n",
      "4.0.conv2.weight        - requires_grad: True\n",
      "4.0.bn2.weight          - requires_grad: True\n",
      "4.0.bn2.bias            - requires_grad: True\n",
      "4.0.conv3.weight        - requires_grad: True\n",
      "4.0.bn3.weight          - requires_grad: True\n",
      "4.0.bn3.bias            - requires_grad: True\n",
      "4.0.downsample.0.weight - requires_grad: True\n",
      "4.0.downsample.1.weight - requires_grad: True\n",
      "4.0.downsample.1.bias   - requires_grad: True\n",
      "4.1.conv1.weight        - requires_grad: True\n",
      "4.1.bn1.weight          - requires_grad: True\n",
      "4.1.bn1.bias            - requires_grad: True\n",
      "4.1.conv2.weight        - requires_grad: True\n",
      "4.1.bn2.weight          - requires_grad: True\n",
      "4.1.bn2.bias            - requires_grad: True\n",
      "4.1.conv3.weight        - requires_grad: True\n",
      "4.1.bn3.weight          - requires_grad: True\n",
      "4.1.bn3.bias            - requires_grad: True\n",
      "4.2.conv1.weight        - requires_grad: True\n",
      "4.2.bn1.weight          - requires_grad: True\n",
      "4.2.bn1.bias            - requires_grad: True\n",
      "4.2.conv2.weight        - requires_grad: True\n",
      "4.2.bn2.weight          - requires_grad: True\n",
      "4.2.bn2.bias            - requires_grad: True\n",
      "4.2.conv3.weight        - requires_grad: True\n",
      "4.2.bn3.weight          - requires_grad: True\n",
      "4.2.bn3.bias            - requires_grad: True\n",
      "5.0.conv1.weight        - requires_grad: True\n",
      "5.0.bn1.weight          - requires_grad: True\n",
      "5.0.bn1.bias            - requires_grad: True\n",
      "5.0.conv2.weight        - requires_grad: True\n",
      "5.0.bn2.weight          - requires_grad: True\n",
      "5.0.bn2.bias            - requires_grad: True\n",
      "5.0.conv3.weight        - requires_grad: True\n",
      "5.0.bn3.weight          - requires_grad: True\n",
      "5.0.bn3.bias            - requires_grad: True\n",
      "5.0.downsample.0.weight - requires_grad: True\n",
      "5.0.downsample.1.weight - requires_grad: True\n",
      "5.0.downsample.1.bias   - requires_grad: True\n",
      "5.1.conv1.weight        - requires_grad: True\n",
      "5.1.bn1.weight          - requires_grad: True\n",
      "5.1.bn1.bias            - requires_grad: True\n",
      "5.1.conv2.weight        - requires_grad: True\n",
      "5.1.bn2.weight          - requires_grad: True\n",
      "5.1.bn2.bias            - requires_grad: True\n",
      "5.1.conv3.weight        - requires_grad: True\n",
      "5.1.bn3.weight          - requires_grad: True\n",
      "5.1.bn3.bias            - requires_grad: True\n",
      "5.2.conv1.weight        - requires_grad: True\n",
      "5.2.bn1.weight          - requires_grad: True\n",
      "5.2.bn1.bias            - requires_grad: True\n",
      "5.2.conv2.weight        - requires_grad: True\n",
      "5.2.bn2.weight          - requires_grad: True\n",
      "5.2.bn2.bias            - requires_grad: True\n",
      "5.2.conv3.weight        - requires_grad: True\n",
      "5.2.bn3.weight          - requires_grad: True\n",
      "5.2.bn3.bias            - requires_grad: True\n",
      "5.3.conv1.weight        - requires_grad: True\n",
      "5.3.bn1.weight          - requires_grad: True\n",
      "5.3.bn1.bias            - requires_grad: True\n",
      "5.3.conv2.weight        - requires_grad: True\n",
      "5.3.bn2.weight          - requires_grad: True\n",
      "5.3.bn2.bias            - requires_grad: True\n",
      "5.3.conv3.weight        - requires_grad: True\n",
      "5.3.bn3.weight          - requires_grad: True\n",
      "5.3.bn3.bias            - requires_grad: True\n",
      "6.0.conv1.weight        - requires_grad: True\n",
      "6.0.bn1.weight          - requires_grad: True\n",
      "6.0.bn1.bias            - requires_grad: True\n",
      "6.0.conv2.weight        - requires_grad: True\n",
      "6.0.bn2.weight          - requires_grad: True\n",
      "6.0.bn2.bias            - requires_grad: True\n",
      "6.0.conv3.weight        - requires_grad: True\n",
      "6.0.bn3.weight          - requires_grad: True\n",
      "6.0.bn3.bias            - requires_grad: True\n",
      "6.0.downsample.0.weight - requires_grad: True\n",
      "6.0.downsample.1.weight - requires_grad: True\n",
      "6.0.downsample.1.bias   - requires_grad: True\n",
      "6.1.conv1.weight        - requires_grad: True\n",
      "6.1.bn1.weight          - requires_grad: True\n",
      "6.1.bn1.bias            - requires_grad: True\n",
      "6.1.conv2.weight        - requires_grad: True\n",
      "6.1.bn2.weight          - requires_grad: True\n",
      "6.1.bn2.bias            - requires_grad: True\n",
      "6.1.conv3.weight        - requires_grad: True\n",
      "6.1.bn3.weight          - requires_grad: True\n",
      "6.1.bn3.bias            - requires_grad: True\n",
      "6.2.conv1.weight        - requires_grad: True\n",
      "6.2.bn1.weight          - requires_grad: True\n",
      "6.2.bn1.bias            - requires_grad: True\n",
      "6.2.conv2.weight        - requires_grad: True\n",
      "6.2.bn2.weight          - requires_grad: True\n",
      "6.2.bn2.bias            - requires_grad: True\n",
      "6.2.conv3.weight        - requires_grad: True\n",
      "6.2.bn3.weight          - requires_grad: True\n",
      "6.2.bn3.bias            - requires_grad: True\n",
      "6.3.conv1.weight        - requires_grad: True\n",
      "6.3.bn1.weight          - requires_grad: True\n",
      "6.3.bn1.bias            - requires_grad: True\n",
      "6.3.conv2.weight        - requires_grad: True\n",
      "6.3.bn2.weight          - requires_grad: True\n",
      "6.3.bn2.bias            - requires_grad: True\n",
      "6.3.conv3.weight        - requires_grad: True\n",
      "6.3.bn3.weight          - requires_grad: True\n",
      "6.3.bn3.bias            - requires_grad: True\n",
      "6.4.conv1.weight        - requires_grad: True\n",
      "6.4.bn1.weight          - requires_grad: True\n",
      "6.4.bn1.bias            - requires_grad: True\n",
      "6.4.conv2.weight        - requires_grad: True\n",
      "6.4.bn2.weight          - requires_grad: True\n",
      "6.4.bn2.bias            - requires_grad: True\n",
      "6.4.conv3.weight        - requires_grad: True\n",
      "6.4.bn3.weight          - requires_grad: True\n",
      "6.4.bn3.bias            - requires_grad: True\n",
      "6.5.conv1.weight        - requires_grad: True\n",
      "6.5.bn1.weight          - requires_grad: True\n",
      "6.5.bn1.bias            - requires_grad: True\n",
      "6.5.conv2.weight        - requires_grad: True\n",
      "6.5.bn2.weight          - requires_grad: True\n",
      "6.5.bn2.bias            - requires_grad: True\n",
      "6.5.conv3.weight        - requires_grad: True\n",
      "6.5.bn3.weight          - requires_grad: True\n",
      "6.5.bn3.bias            - requires_grad: True\n",
      "7.0.conv1.weight        - requires_grad: True\n",
      "7.0.bn1.weight          - requires_grad: True\n",
      "7.0.bn1.bias            - requires_grad: True\n",
      "7.0.conv2.weight        - requires_grad: True\n",
      "7.0.bn2.weight          - requires_grad: True\n",
      "7.0.bn2.bias            - requires_grad: True\n",
      "7.0.conv3.weight        - requires_grad: True\n",
      "7.0.bn3.weight          - requires_grad: True\n",
      "7.0.bn3.bias            - requires_grad: True\n",
      "7.0.downsample.0.weight - requires_grad: True\n",
      "7.0.downsample.1.weight - requires_grad: True\n",
      "7.0.downsample.1.bias   - requires_grad: True\n",
      "7.1.conv1.weight        - requires_grad: True\n",
      "7.1.bn1.weight          - requires_grad: True\n",
      "7.1.bn1.bias            - requires_grad: True\n",
      "7.1.conv2.weight        - requires_grad: True\n",
      "7.1.bn2.weight          - requires_grad: True\n",
      "7.1.bn2.bias            - requires_grad: True\n",
      "7.1.conv3.weight        - requires_grad: True\n",
      "7.1.bn3.weight          - requires_grad: True\n",
      "7.1.bn3.bias            - requires_grad: True\n",
      "7.2.conv1.weight        - requires_grad: True\n",
      "7.2.bn1.weight          - requires_grad: True\n",
      "7.2.bn1.bias            - requires_grad: True\n",
      "7.2.conv2.weight        - requires_grad: True\n",
      "7.2.bn2.weight          - requires_grad: True\n",
      "7.2.bn2.bias            - requires_grad: True\n",
      "7.2.conv3.weight        - requires_grad: True\n",
      "7.2.bn3.weight          - requires_grad: True\n",
      "7.2.bn3.bias            - requires_grad: True\n"
     ]
    }
   ],
   "source": [
    "feature_extractor = nn.Sequential(*list(resnet.children())[:-1])\n",
    "\n",
    "# log\n",
    "for name, param in feature_extractor.named_parameters():\n",
    "    print(f\"{name:<23} - requires_grad: {param.requires_grad}\")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Freeze all transferred layers"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 37,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "conv1.weight                 - requires_grad: False\n",
      "bn1.weight                   - requires_grad: False\n",
      "bn1.bias                     - requires_grad: False\n",
      "layer1.0.conv1.weight        - requires_grad: False\n",
      "layer1.0.bn1.weight          - requires_grad: False\n",
      "layer1.0.bn1.bias            - requires_grad: False\n",
      "layer1.0.conv2.weight        - requires_grad: False\n",
      "layer1.0.bn2.weight          - requires_grad: False\n",
      "layer1.0.bn2.bias            - requires_grad: False\n",
      "layer1.0.conv3.weight        - requires_grad: False\n",
      "layer1.0.bn3.weight          - requires_grad: False\n",
      "layer1.0.bn3.bias            - requires_grad: False\n",
      "layer1.0.downsample.0.weight - requires_grad: False\n",
      "layer1.0.downsample.1.weight - requires_grad: False\n",
      "layer1.0.downsample.1.bias   - requires_grad: False\n",
      "layer1.1.conv1.weight        - requires_grad: False\n",
      "layer1.1.bn1.weight          - requires_grad: False\n",
      "layer1.1.bn1.bias            - requires_grad: False\n",
      "layer1.1.conv2.weight        - requires_grad: False\n",
      "layer1.1.bn2.weight          - requires_grad: False\n",
      "layer1.1.bn2.bias            - requires_grad: False\n",
      "layer1.1.conv3.weight        - requires_grad: False\n",
      "layer1.1.bn3.weight          - requires_grad: False\n",
      "layer1.1.bn3.bias            - requires_grad: False\n",
      "layer1.2.conv1.weight        - requires_grad: False\n",
      "layer1.2.bn1.weight          - requires_grad: False\n",
      "layer1.2.bn1.bias            - requires_grad: False\n",
      "layer1.2.conv2.weight        - requires_grad: False\n",
      "layer1.2.bn2.weight          - requires_grad: False\n",
      "layer1.2.bn2.bias            - requires_grad: False\n",
      "layer1.2.conv3.weight        - requires_grad: False\n",
      "layer1.2.bn3.weight          - requires_grad: False\n",
      "layer1.2.bn3.bias            - requires_grad: False\n",
      "layer2.0.conv1.weight        - requires_grad: False\n",
      "layer2.0.bn1.weight          - requires_grad: False\n",
      "layer2.0.bn1.bias            - requires_grad: False\n",
      "layer2.0.conv2.weight        - requires_grad: False\n",
      "layer2.0.bn2.weight          - requires_grad: False\n",
      "layer2.0.bn2.bias            - requires_grad: False\n",
      "layer2.0.conv3.weight        - requires_grad: False\n",
      "layer2.0.bn3.weight          - requires_grad: False\n",
      "layer2.0.bn3.bias            - requires_grad: False\n",
      "layer2.0.downsample.0.weight - requires_grad: False\n",
      "layer2.0.downsample.1.weight - requires_grad: False\n",
      "layer2.0.downsample.1.bias   - requires_grad: False\n",
      "layer2.1.conv1.weight        - requires_grad: False\n",
      "layer2.1.bn1.weight          - requires_grad: False\n",
      "layer2.1.bn1.bias            - requires_grad: False\n",
      "layer2.1.conv2.weight        - requires_grad: False\n",
      "layer2.1.bn2.weight          - requires_grad: False\n",
      "layer2.1.bn2.bias            - requires_grad: False\n",
      "layer2.1.conv3.weight        - requires_grad: False\n",
      "layer2.1.bn3.weight          - requires_grad: False\n",
      "layer2.1.bn3.bias            - requires_grad: False\n",
      "layer2.2.conv1.weight        - requires_grad: False\n",
      "layer2.2.bn1.weight          - requires_grad: False\n",
      "layer2.2.bn1.bias            - requires_grad: False\n",
      "layer2.2.conv2.weight        - requires_grad: False\n",
      "layer2.2.bn2.weight          - requires_grad: False\n",
      "layer2.2.bn2.bias            - requires_grad: False\n",
      "layer2.2.conv3.weight        - requires_grad: False\n",
      "layer2.2.bn3.weight          - requires_grad: False\n",
      "layer2.2.bn3.bias            - requires_grad: False\n",
      "layer2.3.conv1.weight        - requires_grad: False\n",
      "layer2.3.bn1.weight          - requires_grad: False\n",
      "layer2.3.bn1.bias            - requires_grad: False\n",
      "layer2.3.conv2.weight        - requires_grad: False\n",
      "layer2.3.bn2.weight          - requires_grad: False\n",
      "layer2.3.bn2.bias            - requires_grad: False\n",
      "layer2.3.conv3.weight        - requires_grad: False\n",
      "layer2.3.bn3.weight          - requires_grad: False\n",
      "layer2.3.bn3.bias            - requires_grad: False\n",
      "layer3.0.conv1.weight        - requires_grad: False\n",
      "layer3.0.bn1.weight          - requires_grad: False\n",
      "layer3.0.bn1.bias            - requires_grad: False\n",
      "layer3.0.conv2.weight        - requires_grad: False\n",
      "layer3.0.bn2.weight          - requires_grad: False\n",
      "layer3.0.bn2.bias            - requires_grad: False\n",
      "layer3.0.conv3.weight        - requires_grad: False\n",
      "layer3.0.bn3.weight          - requires_grad: False\n",
      "layer3.0.bn3.bias            - requires_grad: False\n",
      "layer3.0.downsample.0.weight - requires_grad: False\n",
      "layer3.0.downsample.1.weight - requires_grad: False\n",
      "layer3.0.downsample.1.bias   - requires_grad: False\n",
      "layer3.1.conv1.weight        - requires_grad: False\n",
      "layer3.1.bn1.weight          - requires_grad: False\n",
      "layer3.1.bn1.bias            - requires_grad: False\n",
      "layer3.1.conv2.weight        - requires_grad: False\n",
      "layer3.1.bn2.weight          - requires_grad: False\n",
      "layer3.1.bn2.bias            - requires_grad: False\n",
      "layer3.1.conv3.weight        - requires_grad: False\n",
      "layer3.1.bn3.weight          - requires_grad: False\n",
      "layer3.1.bn3.bias            - requires_grad: False\n",
      "layer3.2.conv1.weight        - requires_grad: False\n",
      "layer3.2.bn1.weight          - requires_grad: False\n",
      "layer3.2.bn1.bias            - requires_grad: False\n",
      "layer3.2.conv2.weight        - requires_grad: False\n",
      "layer3.2.bn2.weight          - requires_grad: False\n",
      "layer3.2.bn2.bias            - requires_grad: False\n",
      "layer3.2.conv3.weight        - requires_grad: False\n",
      "layer3.2.bn3.weight          - requires_grad: False\n",
      "layer3.2.bn3.bias            - requires_grad: False\n",
      "layer3.3.conv1.weight        - requires_grad: False\n",
      "layer3.3.bn1.weight          - requires_grad: False\n",
      "layer3.3.bn1.bias            - requires_grad: False\n",
      "layer3.3.conv2.weight        - requires_grad: False\n",
      "layer3.3.bn2.weight          - requires_grad: False\n",
      "layer3.3.bn2.bias            - requires_grad: False\n",
      "layer3.3.conv3.weight        - requires_grad: False\n",
      "layer3.3.bn3.weight          - requires_grad: False\n",
      "layer3.3.bn3.bias            - requires_grad: False\n",
      "layer3.4.conv1.weight        - requires_grad: False\n",
      "layer3.4.bn1.weight          - requires_grad: False\n",
      "layer3.4.bn1.bias            - requires_grad: False\n",
      "layer3.4.conv2.weight        - requires_grad: False\n",
      "layer3.4.bn2.weight          - requires_grad: False\n",
      "layer3.4.bn2.bias            - requires_grad: False\n",
      "layer3.4.conv3.weight        - requires_grad: False\n",
      "layer3.4.bn3.weight          - requires_grad: False\n",
      "layer3.4.bn3.bias            - requires_grad: False\n",
      "layer3.5.conv1.weight        - requires_grad: False\n",
      "layer3.5.bn1.weight          - requires_grad: False\n",
      "layer3.5.bn1.bias            - requires_grad: False\n",
      "layer3.5.conv2.weight        - requires_grad: False\n",
      "layer3.5.bn2.weight          - requires_grad: False\n",
      "layer3.5.bn2.bias            - requires_grad: False\n",
      "layer3.5.conv3.weight        - requires_grad: False\n",
      "layer3.5.bn3.weight          - requires_grad: False\n",
      "layer3.5.bn3.bias            - requires_grad: False\n",
      "layer4.0.conv1.weight        - requires_grad: False\n",
      "layer4.0.bn1.weight          - requires_grad: False\n",
      "layer4.0.bn1.bias            - requires_grad: False\n",
      "layer4.0.conv2.weight        - requires_grad: False\n",
      "layer4.0.bn2.weight          - requires_grad: False\n",
      "layer4.0.bn2.bias            - requires_grad: False\n",
      "layer4.0.conv3.weight        - requires_grad: False\n",
      "layer4.0.bn3.weight          - requires_grad: False\n",
      "layer4.0.bn3.bias            - requires_grad: False\n",
      "layer4.0.downsample.0.weight - requires_grad: False\n",
      "layer4.0.downsample.1.weight - requires_grad: False\n",
      "layer4.0.downsample.1.bias   - requires_grad: False\n",
      "layer4.1.conv1.weight        - requires_grad: False\n",
      "layer4.1.bn1.weight          - requires_grad: False\n",
      "layer4.1.bn1.bias            - requires_grad: False\n",
      "layer4.1.conv2.weight        - requires_grad: False\n",
      "layer4.1.bn2.weight          - requires_grad: False\n",
      "layer4.1.bn2.bias            - requires_grad: False\n",
      "layer4.1.conv3.weight        - requires_grad: False\n",
      "layer4.1.bn3.weight          - requires_grad: False\n",
      "layer4.1.bn3.bias            - requires_grad: False\n",
      "layer4.2.conv1.weight        - requires_grad: False\n",
      "layer4.2.bn1.weight          - requires_grad: False\n",
      "layer4.2.bn1.bias            - requires_grad: False\n",
      "layer4.2.conv2.weight        - requires_grad: False\n",
      "layer4.2.bn2.weight          - requires_grad: False\n",
      "layer4.2.bn2.bias            - requires_grad: False\n",
      "layer4.2.conv3.weight        - requires_grad: False\n",
      "layer4.2.bn3.weight          - requires_grad: False\n",
      "layer4.2.bn3.bias            - requires_grad: False\n",
      "fc.weight                    - requires_grad: False\n",
      "fc.bias                      - requires_grad: False\n"
     ]
    }
   ],
   "source": [
    "for name, param in resnet.named_parameters():\n",
    "    param.requires_grad = False\n",
    "\n",
    "# log\n",
    "for name, param in resnet.named_parameters():\n",
    "    print(f\"{name:<28} - requires_grad: {param.requires_grad}\")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Transfer the model"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 38,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "MyModel(\n",
       "  (feature_extractor): Sequential(\n",
       "    (0): Conv2d(3, 64, kernel_size=(7, 7), stride=(2, 2), padding=(3, 3), bias=False)\n",
       "    (1): BatchNorm2d(64, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
       "    (2): ReLU(inplace=True)\n",
       "    (3): MaxPool2d(kernel_size=3, stride=2, padding=1, dilation=1, ceil_mode=False)\n",
       "    (4): Sequential(\n",
       "      (0): Bottleneck(\n",
       "        (conv1): Conv2d(64, 64, kernel_size=(1, 1), stride=(1, 1), bias=False)\n",
       "        (bn1): BatchNorm2d(64, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
       "        (conv2): Conv2d(64, 64, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), bias=False)\n",
       "        (bn2): BatchNorm2d(64, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
       "        (conv3): Conv2d(64, 256, kernel_size=(1, 1), stride=(1, 1), bias=False)\n",
       "        (bn3): BatchNorm2d(256, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
       "        (relu): ReLU(inplace=True)\n",
       "        (downsample): Sequential(\n",
       "          (0): Conv2d(64, 256, kernel_size=(1, 1), stride=(1, 1), bias=False)\n",
       "          (1): BatchNorm2d(256, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
       "        )\n",
       "      )\n",
       "      (1): Bottleneck(\n",
       "        (conv1): Conv2d(256, 64, kernel_size=(1, 1), stride=(1, 1), bias=False)\n",
       "        (bn1): BatchNorm2d(64, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
       "        (conv2): Conv2d(64, 64, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), bias=False)\n",
       "        (bn2): BatchNorm2d(64, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
       "        (conv3): Conv2d(64, 256, kernel_size=(1, 1), stride=(1, 1), bias=False)\n",
       "        (bn3): BatchNorm2d(256, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
       "        (relu): ReLU(inplace=True)\n",
       "      )\n",
       "      (2): Bottleneck(\n",
       "        (conv1): Conv2d(256, 64, kernel_size=(1, 1), stride=(1, 1), bias=False)\n",
       "        (bn1): BatchNorm2d(64, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
       "        (conv2): Conv2d(64, 64, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), bias=False)\n",
       "        (bn2): BatchNorm2d(64, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
       "        (conv3): Conv2d(64, 256, kernel_size=(1, 1), stride=(1, 1), bias=False)\n",
       "        (bn3): BatchNorm2d(256, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
       "        (relu): ReLU(inplace=True)\n",
       "      )\n",
       "    )\n",
       "    (5): Sequential(\n",
       "      (0): Bottleneck(\n",
       "        (conv1): Conv2d(256, 128, kernel_size=(1, 1), stride=(1, 1), bias=False)\n",
       "        (bn1): BatchNorm2d(128, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
       "        (conv2): Conv2d(128, 128, kernel_size=(3, 3), stride=(2, 2), padding=(1, 1), bias=False)\n",
       "        (bn2): BatchNorm2d(128, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
       "        (conv3): Conv2d(128, 512, kernel_size=(1, 1), stride=(1, 1), bias=False)\n",
       "        (bn3): BatchNorm2d(512, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
       "        (relu): ReLU(inplace=True)\n",
       "        (downsample): Sequential(\n",
       "          (0): Conv2d(256, 512, kernel_size=(1, 1), stride=(2, 2), bias=False)\n",
       "          (1): BatchNorm2d(512, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
       "        )\n",
       "      )\n",
       "      (1): Bottleneck(\n",
       "        (conv1): Conv2d(512, 128, kernel_size=(1, 1), stride=(1, 1), bias=False)\n",
       "        (bn1): BatchNorm2d(128, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
       "        (conv2): Conv2d(128, 128, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), bias=False)\n",
       "        (bn2): BatchNorm2d(128, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
       "        (conv3): Conv2d(128, 512, kernel_size=(1, 1), stride=(1, 1), bias=False)\n",
       "        (bn3): BatchNorm2d(512, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
       "        (relu): ReLU(inplace=True)\n",
       "      )\n",
       "      (2): Bottleneck(\n",
       "        (conv1): Conv2d(512, 128, kernel_size=(1, 1), stride=(1, 1), bias=False)\n",
       "        (bn1): BatchNorm2d(128, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
       "        (conv2): Conv2d(128, 128, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), bias=False)\n",
       "        (bn2): BatchNorm2d(128, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
       "        (conv3): Conv2d(128, 512, kernel_size=(1, 1), stride=(1, 1), bias=False)\n",
       "        (bn3): BatchNorm2d(512, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
       "        (relu): ReLU(inplace=True)\n",
       "      )\n",
       "      (3): Bottleneck(\n",
       "        (conv1): Conv2d(512, 128, kernel_size=(1, 1), stride=(1, 1), bias=False)\n",
       "        (bn1): BatchNorm2d(128, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
       "        (conv2): Conv2d(128, 128, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), bias=False)\n",
       "        (bn2): BatchNorm2d(128, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
       "        (conv3): Conv2d(128, 512, kernel_size=(1, 1), stride=(1, 1), bias=False)\n",
       "        (bn3): BatchNorm2d(512, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
       "        (relu): ReLU(inplace=True)\n",
       "      )\n",
       "    )\n",
       "    (6): Sequential(\n",
       "      (0): Bottleneck(\n",
       "        (conv1): Conv2d(512, 256, kernel_size=(1, 1), stride=(1, 1), bias=False)\n",
       "        (bn1): BatchNorm2d(256, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
       "        (conv2): Conv2d(256, 256, kernel_size=(3, 3), stride=(2, 2), padding=(1, 1), bias=False)\n",
       "        (bn2): BatchNorm2d(256, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
       "        (conv3): Conv2d(256, 1024, kernel_size=(1, 1), stride=(1, 1), bias=False)\n",
       "        (bn3): BatchNorm2d(1024, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
       "        (relu): ReLU(inplace=True)\n",
       "        (downsample): Sequential(\n",
       "          (0): Conv2d(512, 1024, kernel_size=(1, 1), stride=(2, 2), bias=False)\n",
       "          (1): BatchNorm2d(1024, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
       "        )\n",
       "      )\n",
       "      (1): Bottleneck(\n",
       "        (conv1): Conv2d(1024, 256, kernel_size=(1, 1), stride=(1, 1), bias=False)\n",
       "        (bn1): BatchNorm2d(256, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
       "        (conv2): Conv2d(256, 256, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), bias=False)\n",
       "        (bn2): BatchNorm2d(256, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
       "        (conv3): Conv2d(256, 1024, kernel_size=(1, 1), stride=(1, 1), bias=False)\n",
       "        (bn3): BatchNorm2d(1024, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
       "        (relu): ReLU(inplace=True)\n",
       "      )\n",
       "      (2): Bottleneck(\n",
       "        (conv1): Conv2d(1024, 256, kernel_size=(1, 1), stride=(1, 1), bias=False)\n",
       "        (bn1): BatchNorm2d(256, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
       "        (conv2): Conv2d(256, 256, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), bias=False)\n",
       "        (bn2): BatchNorm2d(256, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
       "        (conv3): Conv2d(256, 1024, kernel_size=(1, 1), stride=(1, 1), bias=False)\n",
       "        (bn3): BatchNorm2d(1024, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
       "        (relu): ReLU(inplace=True)\n",
       "      )\n",
       "      (3): Bottleneck(\n",
       "        (conv1): Conv2d(1024, 256, kernel_size=(1, 1), stride=(1, 1), bias=False)\n",
       "        (bn1): BatchNorm2d(256, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
       "        (conv2): Conv2d(256, 256, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), bias=False)\n",
       "        (bn2): BatchNorm2d(256, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
       "        (conv3): Conv2d(256, 1024, kernel_size=(1, 1), stride=(1, 1), bias=False)\n",
       "        (bn3): BatchNorm2d(1024, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
       "        (relu): ReLU(inplace=True)\n",
       "      )\n",
       "      (4): Bottleneck(\n",
       "        (conv1): Conv2d(1024, 256, kernel_size=(1, 1), stride=(1, 1), bias=False)\n",
       "        (bn1): BatchNorm2d(256, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
       "        (conv2): Conv2d(256, 256, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), bias=False)\n",
       "        (bn2): BatchNorm2d(256, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
       "        (conv3): Conv2d(256, 1024, kernel_size=(1, 1), stride=(1, 1), bias=False)\n",
       "        (bn3): BatchNorm2d(1024, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
       "        (relu): ReLU(inplace=True)\n",
       "      )\n",
       "      (5): Bottleneck(\n",
       "        (conv1): Conv2d(1024, 256, kernel_size=(1, 1), stride=(1, 1), bias=False)\n",
       "        (bn1): BatchNorm2d(256, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
       "        (conv2): Conv2d(256, 256, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), bias=False)\n",
       "        (bn2): BatchNorm2d(256, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
       "        (conv3): Conv2d(256, 1024, kernel_size=(1, 1), stride=(1, 1), bias=False)\n",
       "        (bn3): BatchNorm2d(1024, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
       "        (relu): ReLU(inplace=True)\n",
       "      )\n",
       "    )\n",
       "    (7): Sequential(\n",
       "      (0): Bottleneck(\n",
       "        (conv1): Conv2d(1024, 512, kernel_size=(1, 1), stride=(1, 1), bias=False)\n",
       "        (bn1): BatchNorm2d(512, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
       "        (conv2): Conv2d(512, 512, kernel_size=(3, 3), stride=(2, 2), padding=(1, 1), bias=False)\n",
       "        (bn2): BatchNorm2d(512, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
       "        (conv3): Conv2d(512, 2048, kernel_size=(1, 1), stride=(1, 1), bias=False)\n",
       "        (bn3): BatchNorm2d(2048, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
       "        (relu): ReLU(inplace=True)\n",
       "        (downsample): Sequential(\n",
       "          (0): Conv2d(1024, 2048, kernel_size=(1, 1), stride=(2, 2), bias=False)\n",
       "          (1): BatchNorm2d(2048, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
       "        )\n",
       "      )\n",
       "      (1): Bottleneck(\n",
       "        (conv1): Conv2d(2048, 512, kernel_size=(1, 1), stride=(1, 1), bias=False)\n",
       "        (bn1): BatchNorm2d(512, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
       "        (conv2): Conv2d(512, 512, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), bias=False)\n",
       "        (bn2): BatchNorm2d(512, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
       "        (conv3): Conv2d(512, 2048, kernel_size=(1, 1), stride=(1, 1), bias=False)\n",
       "        (bn3): BatchNorm2d(2048, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
       "        (relu): ReLU(inplace=True)\n",
       "      )\n",
       "      (2): Bottleneck(\n",
       "        (conv1): Conv2d(2048, 512, kernel_size=(1, 1), stride=(1, 1), bias=False)\n",
       "        (bn1): BatchNorm2d(512, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
       "        (conv2): Conv2d(512, 512, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), bias=False)\n",
       "        (bn2): BatchNorm2d(512, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
       "        (conv3): Conv2d(512, 2048, kernel_size=(1, 1), stride=(1, 1), bias=False)\n",
       "        (bn3): BatchNorm2d(2048, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
       "        (relu): ReLU(inplace=True)\n",
       "      )\n",
       "    )\n",
       "    (8): AdaptiveAvgPool2d(output_size=(1, 1))\n",
       "  )\n",
       "  (flatten): Flatten(start_dim=1, end_dim=-1)\n",
       "  (classifier): Sequential(\n",
       "    (0): Linear(in_features=2048, out_features=256, bias=True)\n",
       "    (1): ReLU()\n",
       "    (2): Linear(in_features=256, out_features=10, bias=True)\n",
       "  )\n",
       ")"
      ]
     },
     "execution_count": 38,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "class MyModel(torch.nn.Module):\n",
    "    def __init__(self):\n",
    "        super(MyModel, self).__init__()\n",
    "        self.feature_extractor = feature_extractor\n",
    "        self.flatten = nn.Flatten(start_dim= 1)\n",
    "        self.classifier = nn.Sequential(\n",
    "            nn.Linear(2048, 256),\n",
    "            nn.ReLU(),\n",
    "            nn.Linear(256, 10)\n",
    "        )\n",
    "\n",
    "    def forward(self, x):\n",
    "        x = self.feature_extractor(x)\n",
    "        x = self.flatten(x)\n",
    "        x = self.classifier(x)\n",
    "        return x\n",
    "\n",
    "model = MyModel()\n",
    "\n",
    "# log\n",
    "model.to(device)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 39,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "feature_extractor.0.weight                - requires_grad: False\n",
      "feature_extractor.1.weight                - requires_grad: False\n",
      "feature_extractor.1.bias                  - requires_grad: False\n",
      "feature_extractor.4.0.conv1.weight        - requires_grad: False\n",
      "feature_extractor.4.0.bn1.weight          - requires_grad: False\n",
      "feature_extractor.4.0.bn1.bias            - requires_grad: False\n",
      "feature_extractor.4.0.conv2.weight        - requires_grad: False\n",
      "feature_extractor.4.0.bn2.weight          - requires_grad: False\n",
      "feature_extractor.4.0.bn2.bias            - requires_grad: False\n",
      "feature_extractor.4.0.conv3.weight        - requires_grad: False\n",
      "feature_extractor.4.0.bn3.weight          - requires_grad: False\n",
      "feature_extractor.4.0.bn3.bias            - requires_grad: False\n",
      "feature_extractor.4.0.downsample.0.weight - requires_grad: False\n",
      "feature_extractor.4.0.downsample.1.weight - requires_grad: False\n",
      "feature_extractor.4.0.downsample.1.bias   - requires_grad: False\n",
      "feature_extractor.4.1.conv1.weight        - requires_grad: False\n",
      "feature_extractor.4.1.bn1.weight          - requires_grad: False\n",
      "feature_extractor.4.1.bn1.bias            - requires_grad: False\n",
      "feature_extractor.4.1.conv2.weight        - requires_grad: False\n",
      "feature_extractor.4.1.bn2.weight          - requires_grad: False\n",
      "feature_extractor.4.1.bn2.bias            - requires_grad: False\n",
      "feature_extractor.4.1.conv3.weight        - requires_grad: False\n",
      "feature_extractor.4.1.bn3.weight          - requires_grad: False\n",
      "feature_extractor.4.1.bn3.bias            - requires_grad: False\n",
      "feature_extractor.4.2.conv1.weight        - requires_grad: False\n",
      "feature_extractor.4.2.bn1.weight          - requires_grad: False\n",
      "feature_extractor.4.2.bn1.bias            - requires_grad: False\n",
      "feature_extractor.4.2.conv2.weight        - requires_grad: False\n",
      "feature_extractor.4.2.bn2.weight          - requires_grad: False\n",
      "feature_extractor.4.2.bn2.bias            - requires_grad: False\n",
      "feature_extractor.4.2.conv3.weight        - requires_grad: False\n",
      "feature_extractor.4.2.bn3.weight          - requires_grad: False\n",
      "feature_extractor.4.2.bn3.bias            - requires_grad: False\n",
      "feature_extractor.5.0.conv1.weight        - requires_grad: False\n",
      "feature_extractor.5.0.bn1.weight          - requires_grad: False\n",
      "feature_extractor.5.0.bn1.bias            - requires_grad: False\n",
      "feature_extractor.5.0.conv2.weight        - requires_grad: False\n",
      "feature_extractor.5.0.bn2.weight          - requires_grad: False\n",
      "feature_extractor.5.0.bn2.bias            - requires_grad: False\n",
      "feature_extractor.5.0.conv3.weight        - requires_grad: False\n",
      "feature_extractor.5.0.bn3.weight          - requires_grad: False\n",
      "feature_extractor.5.0.bn3.bias            - requires_grad: False\n",
      "feature_extractor.5.0.downsample.0.weight - requires_grad: False\n",
      "feature_extractor.5.0.downsample.1.weight - requires_grad: False\n",
      "feature_extractor.5.0.downsample.1.bias   - requires_grad: False\n",
      "feature_extractor.5.1.conv1.weight        - requires_grad: False\n",
      "feature_extractor.5.1.bn1.weight          - requires_grad: False\n",
      "feature_extractor.5.1.bn1.bias            - requires_grad: False\n",
      "feature_extractor.5.1.conv2.weight        - requires_grad: False\n",
      "feature_extractor.5.1.bn2.weight          - requires_grad: False\n",
      "feature_extractor.5.1.bn2.bias            - requires_grad: False\n",
      "feature_extractor.5.1.conv3.weight        - requires_grad: False\n",
      "feature_extractor.5.1.bn3.weight          - requires_grad: False\n",
      "feature_extractor.5.1.bn3.bias            - requires_grad: False\n",
      "feature_extractor.5.2.conv1.weight        - requires_grad: False\n",
      "feature_extractor.5.2.bn1.weight          - requires_grad: False\n",
      "feature_extractor.5.2.bn1.bias            - requires_grad: False\n",
      "feature_extractor.5.2.conv2.weight        - requires_grad: False\n",
      "feature_extractor.5.2.bn2.weight          - requires_grad: False\n",
      "feature_extractor.5.2.bn2.bias            - requires_grad: False\n",
      "feature_extractor.5.2.conv3.weight        - requires_grad: False\n",
      "feature_extractor.5.2.bn3.weight          - requires_grad: False\n",
      "feature_extractor.5.2.bn3.bias            - requires_grad: False\n",
      "feature_extractor.5.3.conv1.weight        - requires_grad: False\n",
      "feature_extractor.5.3.bn1.weight          - requires_grad: False\n",
      "feature_extractor.5.3.bn1.bias            - requires_grad: False\n",
      "feature_extractor.5.3.conv2.weight        - requires_grad: False\n",
      "feature_extractor.5.3.bn2.weight          - requires_grad: False\n",
      "feature_extractor.5.3.bn2.bias            - requires_grad: False\n",
      "feature_extractor.5.3.conv3.weight        - requires_grad: False\n",
      "feature_extractor.5.3.bn3.weight          - requires_grad: False\n",
      "feature_extractor.5.3.bn3.bias            - requires_grad: False\n",
      "feature_extractor.6.0.conv1.weight        - requires_grad: False\n",
      "feature_extractor.6.0.bn1.weight          - requires_grad: False\n",
      "feature_extractor.6.0.bn1.bias            - requires_grad: False\n",
      "feature_extractor.6.0.conv2.weight        - requires_grad: False\n",
      "feature_extractor.6.0.bn2.weight          - requires_grad: False\n",
      "feature_extractor.6.0.bn2.bias            - requires_grad: False\n",
      "feature_extractor.6.0.conv3.weight        - requires_grad: False\n",
      "feature_extractor.6.0.bn3.weight          - requires_grad: False\n",
      "feature_extractor.6.0.bn3.bias            - requires_grad: False\n",
      "feature_extractor.6.0.downsample.0.weight - requires_grad: False\n",
      "feature_extractor.6.0.downsample.1.weight - requires_grad: False\n",
      "feature_extractor.6.0.downsample.1.bias   - requires_grad: False\n",
      "feature_extractor.6.1.conv1.weight        - requires_grad: False\n",
      "feature_extractor.6.1.bn1.weight          - requires_grad: False\n",
      "feature_extractor.6.1.bn1.bias            - requires_grad: False\n",
      "feature_extractor.6.1.conv2.weight        - requires_grad: False\n",
      "feature_extractor.6.1.bn2.weight          - requires_grad: False\n",
      "feature_extractor.6.1.bn2.bias            - requires_grad: False\n",
      "feature_extractor.6.1.conv3.weight        - requires_grad: False\n",
      "feature_extractor.6.1.bn3.weight          - requires_grad: False\n",
      "feature_extractor.6.1.bn3.bias            - requires_grad: False\n",
      "feature_extractor.6.2.conv1.weight        - requires_grad: False\n",
      "feature_extractor.6.2.bn1.weight          - requires_grad: False\n",
      "feature_extractor.6.2.bn1.bias            - requires_grad: False\n",
      "feature_extractor.6.2.conv2.weight        - requires_grad: False\n",
      "feature_extractor.6.2.bn2.weight          - requires_grad: False\n",
      "feature_extractor.6.2.bn2.bias            - requires_grad: False\n",
      "feature_extractor.6.2.conv3.weight        - requires_grad: False\n",
      "feature_extractor.6.2.bn3.weight          - requires_grad: False\n",
      "feature_extractor.6.2.bn3.bias            - requires_grad: False\n",
      "feature_extractor.6.3.conv1.weight        - requires_grad: False\n",
      "feature_extractor.6.3.bn1.weight          - requires_grad: False\n",
      "feature_extractor.6.3.bn1.bias            - requires_grad: False\n",
      "feature_extractor.6.3.conv2.weight        - requires_grad: False\n",
      "feature_extractor.6.3.bn2.weight          - requires_grad: False\n",
      "feature_extractor.6.3.bn2.bias            - requires_grad: False\n",
      "feature_extractor.6.3.conv3.weight        - requires_grad: False\n",
      "feature_extractor.6.3.bn3.weight          - requires_grad: False\n",
      "feature_extractor.6.3.bn3.bias            - requires_grad: False\n",
      "feature_extractor.6.4.conv1.weight        - requires_grad: False\n",
      "feature_extractor.6.4.bn1.weight          - requires_grad: False\n",
      "feature_extractor.6.4.bn1.bias            - requires_grad: False\n",
      "feature_extractor.6.4.conv2.weight        - requires_grad: False\n",
      "feature_extractor.6.4.bn2.weight          - requires_grad: False\n",
      "feature_extractor.6.4.bn2.bias            - requires_grad: False\n",
      "feature_extractor.6.4.conv3.weight        - requires_grad: False\n",
      "feature_extractor.6.4.bn3.weight          - requires_grad: False\n",
      "feature_extractor.6.4.bn3.bias            - requires_grad: False\n",
      "feature_extractor.6.5.conv1.weight        - requires_grad: False\n",
      "feature_extractor.6.5.bn1.weight          - requires_grad: False\n",
      "feature_extractor.6.5.bn1.bias            - requires_grad: False\n",
      "feature_extractor.6.5.conv2.weight        - requires_grad: False\n",
      "feature_extractor.6.5.bn2.weight          - requires_grad: False\n",
      "feature_extractor.6.5.bn2.bias            - requires_grad: False\n",
      "feature_extractor.6.5.conv3.weight        - requires_grad: False\n",
      "feature_extractor.6.5.bn3.weight          - requires_grad: False\n",
      "feature_extractor.6.5.bn3.bias            - requires_grad: False\n",
      "feature_extractor.7.0.conv1.weight        - requires_grad: False\n",
      "feature_extractor.7.0.bn1.weight          - requires_grad: False\n",
      "feature_extractor.7.0.bn1.bias            - requires_grad: False\n",
      "feature_extractor.7.0.conv2.weight        - requires_grad: False\n",
      "feature_extractor.7.0.bn2.weight          - requires_grad: False\n",
      "feature_extractor.7.0.bn2.bias            - requires_grad: False\n",
      "feature_extractor.7.0.conv3.weight        - requires_grad: False\n",
      "feature_extractor.7.0.bn3.weight          - requires_grad: False\n",
      "feature_extractor.7.0.bn3.bias            - requires_grad: False\n",
      "feature_extractor.7.0.downsample.0.weight - requires_grad: False\n",
      "feature_extractor.7.0.downsample.1.weight - requires_grad: False\n",
      "feature_extractor.7.0.downsample.1.bias   - requires_grad: False\n",
      "feature_extractor.7.1.conv1.weight        - requires_grad: False\n",
      "feature_extractor.7.1.bn1.weight          - requires_grad: False\n",
      "feature_extractor.7.1.bn1.bias            - requires_grad: False\n",
      "feature_extractor.7.1.conv2.weight        - requires_grad: False\n",
      "feature_extractor.7.1.bn2.weight          - requires_grad: False\n",
      "feature_extractor.7.1.bn2.bias            - requires_grad: False\n",
      "feature_extractor.7.1.conv3.weight        - requires_grad: False\n",
      "feature_extractor.7.1.bn3.weight          - requires_grad: False\n",
      "feature_extractor.7.1.bn3.bias            - requires_grad: False\n",
      "feature_extractor.7.2.conv1.weight        - requires_grad: False\n",
      "feature_extractor.7.2.bn1.weight          - requires_grad: False\n",
      "feature_extractor.7.2.bn1.bias            - requires_grad: False\n",
      "feature_extractor.7.2.conv2.weight        - requires_grad: False\n",
      "feature_extractor.7.2.bn2.weight          - requires_grad: False\n",
      "feature_extractor.7.2.bn2.bias            - requires_grad: False\n",
      "feature_extractor.7.2.conv3.weight        - requires_grad: False\n",
      "feature_extractor.7.2.bn3.weight          - requires_grad: False\n",
      "feature_extractor.7.2.bn3.bias            - requires_grad: False\n",
      "classifier.0.weight                       - requires_grad: True\n",
      "classifier.0.bias                         - requires_grad: True\n",
      "classifier.2.weight                       - requires_grad: True\n",
      "classifier.2.bias                         - requires_grad: True\n"
     ]
    }
   ],
   "source": [
    "for name, param in model.named_parameters():\n",
    "    print(f\"{name:<41} - requires_grad: {param.requires_grad}\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 40,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "----------------------------------------------------------------\n",
      "        Layer (type)               Output Shape         Param #\n",
      "================================================================\n",
      "            Conv2d-1           [-1, 64, 16, 16]           9,408\n",
      "       BatchNorm2d-2           [-1, 64, 16, 16]             128\n",
      "              ReLU-3           [-1, 64, 16, 16]               0\n",
      "         MaxPool2d-4             [-1, 64, 8, 8]               0\n",
      "            Conv2d-5             [-1, 64, 8, 8]           4,096\n",
      "       BatchNorm2d-6             [-1, 64, 8, 8]             128\n",
      "              ReLU-7             [-1, 64, 8, 8]               0\n",
      "            Conv2d-8             [-1, 64, 8, 8]          36,864\n",
      "       BatchNorm2d-9             [-1, 64, 8, 8]             128\n",
      "             ReLU-10             [-1, 64, 8, 8]               0\n",
      "           Conv2d-11            [-1, 256, 8, 8]          16,384\n",
      "      BatchNorm2d-12            [-1, 256, 8, 8]             512\n",
      "           Conv2d-13            [-1, 256, 8, 8]          16,384\n",
      "      BatchNorm2d-14            [-1, 256, 8, 8]             512\n",
      "             ReLU-15            [-1, 256, 8, 8]               0\n",
      "       Bottleneck-16            [-1, 256, 8, 8]               0\n",
      "           Conv2d-17             [-1, 64, 8, 8]          16,384\n",
      "      BatchNorm2d-18             [-1, 64, 8, 8]             128\n",
      "             ReLU-19             [-1, 64, 8, 8]               0\n",
      "           Conv2d-20             [-1, 64, 8, 8]          36,864\n",
      "      BatchNorm2d-21             [-1, 64, 8, 8]             128\n",
      "             ReLU-22             [-1, 64, 8, 8]               0\n",
      "           Conv2d-23            [-1, 256, 8, 8]          16,384\n",
      "      BatchNorm2d-24            [-1, 256, 8, 8]             512\n",
      "             ReLU-25            [-1, 256, 8, 8]               0\n",
      "       Bottleneck-26            [-1, 256, 8, 8]               0\n",
      "           Conv2d-27             [-1, 64, 8, 8]          16,384\n",
      "      BatchNorm2d-28             [-1, 64, 8, 8]             128\n",
      "             ReLU-29             [-1, 64, 8, 8]               0\n",
      "           Conv2d-30             [-1, 64, 8, 8]          36,864\n",
      "      BatchNorm2d-31             [-1, 64, 8, 8]             128\n",
      "             ReLU-32             [-1, 64, 8, 8]               0\n",
      "           Conv2d-33            [-1, 256, 8, 8]          16,384\n",
      "      BatchNorm2d-34            [-1, 256, 8, 8]             512\n",
      "             ReLU-35            [-1, 256, 8, 8]               0\n",
      "       Bottleneck-36            [-1, 256, 8, 8]               0\n",
      "           Conv2d-37            [-1, 128, 8, 8]          32,768\n",
      "      BatchNorm2d-38            [-1, 128, 8, 8]             256\n",
      "             ReLU-39            [-1, 128, 8, 8]               0\n",
      "           Conv2d-40            [-1, 128, 4, 4]         147,456\n",
      "      BatchNorm2d-41            [-1, 128, 4, 4]             256\n",
      "             ReLU-42            [-1, 128, 4, 4]               0\n",
      "           Conv2d-43            [-1, 512, 4, 4]          65,536\n",
      "      BatchNorm2d-44            [-1, 512, 4, 4]           1,024\n",
      "           Conv2d-45            [-1, 512, 4, 4]         131,072\n",
      "      BatchNorm2d-46            [-1, 512, 4, 4]           1,024\n",
      "             ReLU-47            [-1, 512, 4, 4]               0\n",
      "       Bottleneck-48            [-1, 512, 4, 4]               0\n",
      "           Conv2d-49            [-1, 128, 4, 4]          65,536\n",
      "      BatchNorm2d-50            [-1, 128, 4, 4]             256\n",
      "             ReLU-51            [-1, 128, 4, 4]               0\n",
      "           Conv2d-52            [-1, 128, 4, 4]         147,456\n",
      "      BatchNorm2d-53            [-1, 128, 4, 4]             256\n",
      "             ReLU-54            [-1, 128, 4, 4]               0\n",
      "           Conv2d-55            [-1, 512, 4, 4]          65,536\n",
      "      BatchNorm2d-56            [-1, 512, 4, 4]           1,024\n",
      "             ReLU-57            [-1, 512, 4, 4]               0\n",
      "       Bottleneck-58            [-1, 512, 4, 4]               0\n",
      "           Conv2d-59            [-1, 128, 4, 4]          65,536\n",
      "      BatchNorm2d-60            [-1, 128, 4, 4]             256\n",
      "             ReLU-61            [-1, 128, 4, 4]               0\n",
      "           Conv2d-62            [-1, 128, 4, 4]         147,456\n",
      "      BatchNorm2d-63            [-1, 128, 4, 4]             256\n",
      "             ReLU-64            [-1, 128, 4, 4]               0\n",
      "           Conv2d-65            [-1, 512, 4, 4]          65,536\n",
      "      BatchNorm2d-66            [-1, 512, 4, 4]           1,024\n",
      "             ReLU-67            [-1, 512, 4, 4]               0\n",
      "       Bottleneck-68            [-1, 512, 4, 4]               0\n",
      "           Conv2d-69            [-1, 128, 4, 4]          65,536\n",
      "      BatchNorm2d-70            [-1, 128, 4, 4]             256\n",
      "             ReLU-71            [-1, 128, 4, 4]               0\n",
      "           Conv2d-72            [-1, 128, 4, 4]         147,456\n",
      "      BatchNorm2d-73            [-1, 128, 4, 4]             256\n",
      "             ReLU-74            [-1, 128, 4, 4]               0\n",
      "           Conv2d-75            [-1, 512, 4, 4]          65,536\n",
      "      BatchNorm2d-76            [-1, 512, 4, 4]           1,024\n",
      "             ReLU-77            [-1, 512, 4, 4]               0\n",
      "       Bottleneck-78            [-1, 512, 4, 4]               0\n",
      "           Conv2d-79            [-1, 256, 4, 4]         131,072\n",
      "      BatchNorm2d-80            [-1, 256, 4, 4]             512\n",
      "             ReLU-81            [-1, 256, 4, 4]               0\n",
      "           Conv2d-82            [-1, 256, 2, 2]         589,824\n",
      "      BatchNorm2d-83            [-1, 256, 2, 2]             512\n",
      "             ReLU-84            [-1, 256, 2, 2]               0\n",
      "           Conv2d-85           [-1, 1024, 2, 2]         262,144\n",
      "      BatchNorm2d-86           [-1, 1024, 2, 2]           2,048\n",
      "           Conv2d-87           [-1, 1024, 2, 2]         524,288\n",
      "      BatchNorm2d-88           [-1, 1024, 2, 2]           2,048\n",
      "             ReLU-89           [-1, 1024, 2, 2]               0\n",
      "       Bottleneck-90           [-1, 1024, 2, 2]               0\n",
      "           Conv2d-91            [-1, 256, 2, 2]         262,144\n",
      "      BatchNorm2d-92            [-1, 256, 2, 2]             512\n",
      "             ReLU-93            [-1, 256, 2, 2]               0\n",
      "           Conv2d-94            [-1, 256, 2, 2]         589,824\n",
      "      BatchNorm2d-95            [-1, 256, 2, 2]             512\n",
      "             ReLU-96            [-1, 256, 2, 2]               0\n",
      "           Conv2d-97           [-1, 1024, 2, 2]         262,144\n",
      "      BatchNorm2d-98           [-1, 1024, 2, 2]           2,048\n",
      "             ReLU-99           [-1, 1024, 2, 2]               0\n",
      "      Bottleneck-100           [-1, 1024, 2, 2]               0\n",
      "          Conv2d-101            [-1, 256, 2, 2]         262,144\n",
      "     BatchNorm2d-102            [-1, 256, 2, 2]             512\n",
      "            ReLU-103            [-1, 256, 2, 2]               0\n",
      "          Conv2d-104            [-1, 256, 2, 2]         589,824\n",
      "     BatchNorm2d-105            [-1, 256, 2, 2]             512\n",
      "            ReLU-106            [-1, 256, 2, 2]               0\n",
      "          Conv2d-107           [-1, 1024, 2, 2]         262,144\n",
      "     BatchNorm2d-108           [-1, 1024, 2, 2]           2,048\n",
      "            ReLU-109           [-1, 1024, 2, 2]               0\n",
      "      Bottleneck-110           [-1, 1024, 2, 2]               0\n",
      "          Conv2d-111            [-1, 256, 2, 2]         262,144\n",
      "     BatchNorm2d-112            [-1, 256, 2, 2]             512\n",
      "            ReLU-113            [-1, 256, 2, 2]               0\n",
      "          Conv2d-114            [-1, 256, 2, 2]         589,824\n",
      "     BatchNorm2d-115            [-1, 256, 2, 2]             512\n",
      "            ReLU-116            [-1, 256, 2, 2]               0\n",
      "          Conv2d-117           [-1, 1024, 2, 2]         262,144\n",
      "     BatchNorm2d-118           [-1, 1024, 2, 2]           2,048\n",
      "            ReLU-119           [-1, 1024, 2, 2]               0\n",
      "      Bottleneck-120           [-1, 1024, 2, 2]               0\n",
      "          Conv2d-121            [-1, 256, 2, 2]         262,144\n",
      "     BatchNorm2d-122            [-1, 256, 2, 2]             512\n",
      "            ReLU-123            [-1, 256, 2, 2]               0\n",
      "          Conv2d-124            [-1, 256, 2, 2]         589,824\n",
      "     BatchNorm2d-125            [-1, 256, 2, 2]             512\n",
      "            ReLU-126            [-1, 256, 2, 2]               0\n",
      "          Conv2d-127           [-1, 1024, 2, 2]         262,144\n",
      "     BatchNorm2d-128           [-1, 1024, 2, 2]           2,048\n",
      "            ReLU-129           [-1, 1024, 2, 2]               0\n",
      "      Bottleneck-130           [-1, 1024, 2, 2]               0\n",
      "          Conv2d-131            [-1, 256, 2, 2]         262,144\n",
      "     BatchNorm2d-132            [-1, 256, 2, 2]             512\n",
      "            ReLU-133            [-1, 256, 2, 2]               0\n",
      "          Conv2d-134            [-1, 256, 2, 2]         589,824\n",
      "     BatchNorm2d-135            [-1, 256, 2, 2]             512\n",
      "            ReLU-136            [-1, 256, 2, 2]               0\n",
      "          Conv2d-137           [-1, 1024, 2, 2]         262,144\n",
      "     BatchNorm2d-138           [-1, 1024, 2, 2]           2,048\n",
      "            ReLU-139           [-1, 1024, 2, 2]               0\n",
      "      Bottleneck-140           [-1, 1024, 2, 2]               0\n",
      "          Conv2d-141            [-1, 512, 2, 2]         524,288\n",
      "     BatchNorm2d-142            [-1, 512, 2, 2]           1,024\n",
      "            ReLU-143            [-1, 512, 2, 2]               0\n",
      "          Conv2d-144            [-1, 512, 1, 1]       2,359,296\n",
      "     BatchNorm2d-145            [-1, 512, 1, 1]           1,024\n",
      "            ReLU-146            [-1, 512, 1, 1]               0\n",
      "          Conv2d-147           [-1, 2048, 1, 1]       1,048,576\n",
      "     BatchNorm2d-148           [-1, 2048, 1, 1]           4,096\n",
      "          Conv2d-149           [-1, 2048, 1, 1]       2,097,152\n",
      "     BatchNorm2d-150           [-1, 2048, 1, 1]           4,096\n",
      "            ReLU-151           [-1, 2048, 1, 1]               0\n",
      "      Bottleneck-152           [-1, 2048, 1, 1]               0\n",
      "          Conv2d-153            [-1, 512, 1, 1]       1,048,576\n",
      "     BatchNorm2d-154            [-1, 512, 1, 1]           1,024\n",
      "            ReLU-155            [-1, 512, 1, 1]               0\n",
      "          Conv2d-156            [-1, 512, 1, 1]       2,359,296\n",
      "     BatchNorm2d-157            [-1, 512, 1, 1]           1,024\n",
      "            ReLU-158            [-1, 512, 1, 1]               0\n",
      "          Conv2d-159           [-1, 2048, 1, 1]       1,048,576\n",
      "     BatchNorm2d-160           [-1, 2048, 1, 1]           4,096\n",
      "            ReLU-161           [-1, 2048, 1, 1]               0\n",
      "      Bottleneck-162           [-1, 2048, 1, 1]               0\n",
      "          Conv2d-163            [-1, 512, 1, 1]       1,048,576\n",
      "     BatchNorm2d-164            [-1, 512, 1, 1]           1,024\n",
      "            ReLU-165            [-1, 512, 1, 1]               0\n",
      "          Conv2d-166            [-1, 512, 1, 1]       2,359,296\n",
      "     BatchNorm2d-167            [-1, 512, 1, 1]           1,024\n",
      "            ReLU-168            [-1, 512, 1, 1]               0\n",
      "          Conv2d-169           [-1, 2048, 1, 1]       1,048,576\n",
      "     BatchNorm2d-170           [-1, 2048, 1, 1]           4,096\n",
      "            ReLU-171           [-1, 2048, 1, 1]               0\n",
      "      Bottleneck-172           [-1, 2048, 1, 1]               0\n",
      "AdaptiveAvgPool2d-173           [-1, 2048, 1, 1]               0\n",
      "         Flatten-174                 [-1, 2048]               0\n",
      "          Linear-175                  [-1, 256]         524,544\n",
      "            ReLU-176                  [-1, 256]               0\n",
      "          Linear-177                   [-1, 10]           2,570\n",
      "================================================================\n",
      "Total params: 24,035,146\n",
      "Trainable params: 527,114\n",
      "Non-trainable params: 23,508,032\n",
      "----------------------------------------------------------------\n",
      "Input size (MB): 0.01\n",
      "Forward/backward pass size (MB): 5.88\n",
      "Params size (MB): 91.69\n",
      "Estimated Total Size (MB): 97.58\n",
      "----------------------------------------------------------------\n"
     ]
    }
   ],
   "source": [
    "summary(model, input_size= trainset[0][0].shape)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Set up remaining Hyper-Parameters"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 41,
   "metadata": {},
   "outputs": [],
   "source": [
    "lr = 0.001\n",
    "criterion = nn.CrossEntropyLoss()\n",
    "optimizer = Adam(params= model.parameters(), lr= lr)\n",
    "num_epochs = 10"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Train Loop"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 42,
   "metadata": {},
   "outputs": [],
   "source": [
    "train_acc_per_epoch  = []\n",
    "train_loss_per_epoch = []\n",
    "train_acc = Accuracy(task = 'multiclass', num_classes= len(testset.classes), top_k= 1).to(device)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 43,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "epoch  0  ->  train[loss: 1.59628 - acc: 0.44]\n",
      "epoch  1  ->  train[loss: 1.43106 - acc: 0.50]\n",
      "epoch  2  ->  train[loss: 1.37999 - acc: 0.51]\n",
      "epoch  3  ->  train[loss: 1.33256 - acc: 0.53]\n",
      "epoch  4  ->  train[loss: 1.30345 - acc: 0.54]\n",
      "epoch  5  ->  train[loss: 1.28488 - acc: 0.55]\n",
      "epoch  6  ->  train[loss: 1.27021 - acc: 0.56]\n",
      "epoch  7  ->  train[loss: 1.24872 - acc: 0.56]\n",
      "epoch  8  ->  train[loss: 1.22770 - acc: 0.57]\n",
      "epoch  9  ->  train[loss: 1.22132 - acc: 0.57]\n"
     ]
    }
   ],
   "source": [
    "for epoch in range(num_epochs):\n",
    "\n",
    "    model.train()\n",
    "    train_loss = 0\n",
    "\n",
    "    for x, y in trainloader:\n",
    "\n",
    "        # send data to GPU\n",
    "        x, y_true = x.to(device), y.to(device)\n",
    "\n",
    "        # forward\n",
    "        y_pred = model(x)\n",
    "        loss = criterion(y_pred, y_true)\n",
    "\n",
    "        # backward\n",
    "        loss.backward()\n",
    "\n",
    "        # update parameters\n",
    "        optimizer.step()\n",
    "        optimizer.zero_grad()\n",
    "\n",
    "        # log loss & accuracy\n",
    "        train_loss += loss.item() * len(x)\n",
    "        train_acc.update(y_pred, y_true)\n",
    "\n",
    "    train_loss_per_epoch.append(train_loss / len(trainset))\n",
    "    train_acc_per_epoch.append(train_acc.compute().item())\n",
    "    train_acc.reset()\n",
    "\n",
    "    # log\n",
    "    print(f\"epoch {epoch:>2}  ->  train[loss: {train_loss_per_epoch[epoch]:.5f} - acc: {train_acc_per_epoch[epoch]:.2f}]\")\n"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.12.2"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}

{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Dependencies"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [],
   "source": [
    "import torch\n",
    "from torch.nn import BCELoss\n",
    "from torch.optim import SGD\n",
    "\n",
    "import numpy as np\n",
    "from sklearn import datasets\n",
    "import matplotlib.pyplot as plt"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Logistic Regression\n",
    "<div style=\"display: flex; margin-top: 50px;\">\n",
    "    <div style=\"width: 20%;\">\n",
    "        <table style=\"margin-left: auto; margin-right: auto;\">\n",
    "            <caption>Dataset</caption>\n",
    "            <tr>\n",
    "                <th>#</th>\n",
    "                <th><span style=\"color: cyan;\">x<sub>1</span></th>\n",
    "                <th><span style=\"color: #FF9999;\">y</span></th>\n",
    "            </tr>\n",
    "            <tr>\n",
    "                <th><span style=\"color: #99DD00\">1</span></th>\n",
    "                <td>1</td>\n",
    "                <td>0</td>\n",
    "            </tr>\n",
    "            <tr>\n",
    "                <th><span style=\"color: #99DD00\">2</span></th>\n",
    "                <td>2</td>\n",
    "                <td>0</td>\n",
    "            </tr>\n",
    "            <tr>\n",
    "                <th><span style=\"color: #99DD00\">3</span></th>\n",
    "                <td>3</td>\n",
    "                <td>0</td>\n",
    "            </tr>\n",
    "            <tr>\n",
    "                <th><span style=\"color: #99DD00\">4</span></th>\n",
    "                <td>4</td>\n",
    "                <td>1</td>\n",
    "            </tr>\n",
    "            <tr>\n",
    "                <th><span style=\"color: #99DD00\">5</span></th>\n",
    "                <td>5</td>\n",
    "                <td>1</td>\n",
    "            </tr>\n",
    "            <tr>\n",
    "                <th><span style=\"color: #99DD00\">6</span></th>\n",
    "                <td>6</td>\n",
    "                <td>1</td>\n",
    "            </tr>\n",
    "        </table>\n",
    "    </div>\n",
    "    <div style=\"width: 80%;\">\n",
    "        <img src=\"./resources/images/logistic-regression.svg\" alt=\"Your Image\" style=\"width: 100%;\">\n",
    "    </div>\n",
    "</div>"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# generate artificial data\n",
    "n_samples, n_features = 10, 2\n",
    "\n",
    "x, y = datasets.make_classification(\n",
    "    n_samples= n_samples,\n",
    "    n_features= n_features,\n",
    "    n_informative= 2,\n",
    "    n_redundant= 0,\n",
    "    n_clusters_per_class= 1,\n",
    "    random_state= 42\n",
    ")\n",
    "\n",
    "# convert numpy.ndarray to torch.Tensor\n",
    "train_x = torch.from_numpy(x.astype(np.float32))\n",
    "train_y = torch.from_numpy(y.astype(np.float32)).view(-1, 1)\n",
    "\n",
    "# plot\n",
    "plt.scatter(x[y == 0][:, 0], x[y == 0][:, 1], color= 'b', label= 'Class 0')\n",
    "plt.scatter(x[y == 1][:, 0], x[y == 1][:, 1], color= 'r', label= 'Class 1')\n",
    "plt.xlabel('x_1')\n",
    "plt.ylabel('x_2')\n",
    "plt.legend()\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "LogisticRegression(\n",
       "  (classifier): Linear(in_features=2, out_features=1, bias=True)\n",
       ")"
      ]
     },
     "execution_count": 3,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# custom model for 'logistic regression'\n",
    "class LogisticRegression(torch.nn.Module):\n",
    "    def __init__(self, input_dim, output_dim):\n",
    "        super(LogisticRegression, self).__init__()\n",
    "        self.classifier = torch.nn.Linear(input_dim, output_dim)\n",
    "    \n",
    "    def forward(self, x):\n",
    "        x = self.classifier(x)\n",
    "        x = torch.sigmoid(x)\n",
    "        return x\n",
    "\n",
    "model = LogisticRegression(n_features, 1)\n",
    "\n",
    "model"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "epoch: 0 -> loss: 0.38442\n",
      "epoch: 1 -> loss: 0.34141\n",
      "epoch: 2 -> loss: 0.30671\n",
      "epoch: 3 -> loss: 0.27825\n",
      "epoch: 4 -> loss: 0.25456\n",
      "epoch: 5 -> loss: 0.23458\n"
     ]
    }
   ],
   "source": [
    "# plot stuff\n",
    "state = []\n",
    "\n",
    "# initial weights\n",
    "with torch.no_grad():\n",
    "    # b [w_0] = +1\n",
    "    model.classifier.bias[0].fill_(1)\n",
    "\n",
    "    # w_1 = -1\n",
    "    model.classifier.weight[0, 0].fill_(-1)\n",
    "\n",
    "    # w_2 = +1\n",
    "    model.classifier.weight[0, 1].fill_(1)\n",
    "\n",
    "# hyper parameters\n",
    "epoch = 6\n",
    "lr = .5\n",
    "criterion = BCELoss()\n",
    "optimizer = SGD(model.parameters(), lr= lr)\n",
    "\n",
    "# training loop\n",
    "model.train()\n",
    "for i in range(epoch):\n",
    "\n",
    "    # forward\n",
    "    y_pred = model(train_x)\n",
    "\n",
    "    # backward\n",
    "    loss = criterion(y_pred, train_y)\n",
    "    loss.backward()\n",
    "\n",
    "    # save new y_pred every 5 epochs [plot stuff]\n",
    "    state.append([model.classifier.weight.clone().detach().numpy(), model.classifier.bias.clone().detach().numpy()])\n",
    "\n",
    "    # update parameters\n",
    "    optimizer.step()\n",
    "    optimizer.zero_grad()\n",
    "\n",
    "    # log\n",
    "    print(f\"epoch: {i} -> loss: {loss.item():>7.5f}\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# plot\n",
    "fig, axs = plt.subplots(nrows= 3, ncols= 2, figsize= (12, 16), layout= 'compressed')\n",
    "\n",
    "for row in range(3):\n",
    "    for col in range(2):\n",
    "        axs[row, col].scatter(x[y == 0][:, 0], x[y == 0][:, 1], color= 'b', label= 'Class 0')\n",
    "        axs[row, col].scatter(x[y == 1][:, 0], x[y == 1][:, 1], color= 'r', label= 'Class 1')\n",
    "        axs[row, col].set(title= f\"epoch {row * 2 + col}, W: {state[row * 2 + col][0].squeeze()}, b: {state[row * 2 + col][1].squeeze():.3f}\", xlim= (x[:, 0].min() - 1, x[:, 0].max() + 1), ylim= (x[:, 1].min() - 1, x[:, 1].max() + 1))\n",
    "\n",
    "        # decision boundary\n",
    "        w, b = state[row * 2 + col]\n",
    "        slope = -w[0][0] / w[0][1]\n",
    "        intercept = -b[0] / w[0][1]\n",
    "        x_plot = np.array([np.min(x[:, 0]), np.max(x[:, 0])])\n",
    "        y_plot = slope * x_plot + intercept\n",
    "\n",
    "        axs[row, col].plot(x_plot, y_plot, color='g', linestyle='--', label='Decision Boundary')\n",
    "        axs[row, col].legend()\n",
    "\n",
    "plt.show()"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.12.2"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}

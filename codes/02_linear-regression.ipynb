{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Dependencies"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 24,
   "metadata": {},
   "outputs": [],
   "source": [
    "import numpy as np\n",
    "\n",
    "import torch\n",
    "from torch.optim import SGD\n",
    "from torch.nn import Linear, MSELoss\n",
    "\n",
    "import matplotlib.pyplot as plt\n",
    "\n",
    "from sklearn import datasets"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Linear Regression"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Implementation 1\n",
    "<ul>\n",
    "    <li style=\"font-family: consolas;\">prediction : <span style=\"color: red\">Manual</span></li>\n",
    "    <li style=\"font-family: consolas;\">gradient &nbsp;&nbsp;: <span style=\"color: red\">Manual</span></li>\n",
    "    <li style=\"font-family: consolas;\">loss &nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;: <span style=\"color: red\">Manual</span></li>\n",
    "    <li style=\"font-family: consolas;\">update &nbsp;&nbsp;&nbsp;&nbsp;: <span style=\"color: red\">Manual</span></li>\n",
    "    \n",
    "</ul>"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 25,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "epoch:  1 -> f(6)=  2.640 | loss= 44.00000 | w_old= 0.000 | step= -0.44000 | w_new= 0.440\n",
      "epoch:  2 -> f(6)=  4.699 | loss= 26.76960 | w_old= 0.440 | step= -0.34320 | w_new= 0.783\n",
      "epoch:  3 -> f(6)=  6.305 | loss= 16.28662 | w_old= 0.783 | step= -0.26770 | w_new= 1.051\n",
      "epoch:  4 -> f(6)=  7.558 | loss=  9.90878 | w_old= 1.051 | step= -0.20880 | w_new= 1.260\n",
      "epoch:  5 -> f(6)=  8.535 | loss=  6.02850 | w_old= 1.260 | step= -0.16287 | w_new= 1.423\n",
      "epoch:  6 -> f(6)=  9.298 | loss=  3.66774 | w_old= 1.423 | step= -0.12704 | w_new= 1.550\n",
      "epoch:  7 -> f(6)=  9.892 | loss=  2.23145 | w_old= 1.550 | step= -0.09909 | w_new= 1.649\n",
      "epoch:  8 -> f(6)= 10.356 | loss=  1.35762 | w_old= 1.649 | step= -0.07729 | w_new= 1.726\n",
      "epoch:  9 -> f(6)= 10.718 | loss=  0.82597 | w_old= 1.726 | step= -0.06029 | w_new= 1.786\n",
      "epoch: 10 -> f(6)= 11.000 | loss=  0.50252 | w_old= 1.786 | step= -0.04702 | w_new= 1.833\n",
      "epoch: 11 -> f(6)= 11.220 | loss=  0.30573 | w_old= 1.833 | step= -0.03668 | w_new= 1.870\n",
      "epoch: 12 -> f(6)= 11.391 | loss=  0.18601 | w_old= 1.870 | step= -0.02861 | w_new= 1.899\n",
      "epoch: 13 -> f(6)= 11.525 | loss=  0.11317 | w_old= 1.899 | step= -0.02231 | w_new= 1.921\n",
      "epoch: 14 -> f(6)= 11.630 | loss=  0.06885 | w_old= 1.921 | step= -0.01741 | w_new= 1.938\n",
      "epoch: 15 -> f(6)= 11.711 | loss=  0.04189 | w_old= 1.938 | step= -0.01358 | w_new= 1.952\n",
      "epoch: 16 -> f(6)= 11.775 | loss=  0.02549 | w_old= 1.952 | step= -0.01059 | w_new= 1.962\n",
      "epoch: 17 -> f(6)= 11.824 | loss=  0.01551 | w_old= 1.962 | step= -0.00826 | w_new= 1.971\n",
      "epoch: 18 -> f(6)= 11.863 | loss=  0.00943 | w_old= 1.971 | step= -0.00644 | w_new= 1.977\n",
      "epoch: 19 -> f(6)= 11.893 | loss=  0.00574 | w_old= 1.977 | step= -0.00503 | w_new= 1.982\n",
      "epoch: 20 -> f(6)= 11.917 | loss=  0.00349 | w_old= 1.982 | step= -0.00392 | w_new= 1.986\n"
     ]
    }
   ],
   "source": [
    "# f(x) = 2x\n",
    "train_x = np.array([1, 2, 3, 4, 5] , dtype= np.float32)\n",
    "train_y = np.array([2, 4, 6, 8, 10], dtype= np.float32)\n",
    "\n",
    "# initial weight\n",
    "w = 0.0\n",
    "\n",
    "# feed-forward\n",
    "def forward(x):\n",
    "    return w * x\n",
    "\n",
    "# MSE loss\n",
    "def loss(y_pred, train_y):\n",
    "    return ((y_pred - train_y) ** 2).mean()\n",
    "\n",
    "# backward\n",
    "def gradient(x):\n",
    "    # MSE   = 1/N * (w*x - y) ** 2\n",
    "    # dl/dw = 1/N * 2x * (y - w*x)\n",
    "    return (2 * x * (w * x - train_y)).mean()\n",
    "\n",
    "# hyper parameters\n",
    "lr = 0.01\n",
    "epoch = 20\n",
    "\n",
    "for i in range(epoch):\n",
    "\n",
    "    # forward\n",
    "    y_pred = forward(train_x)\n",
    "\n",
    "    # backward\n",
    "    l = loss(y_pred, train_y)\n",
    "    dw = gradient(train_x)\n",
    "\n",
    "    # update parameters\n",
    "    w -= lr * dw\n",
    "\n",
    "    # test\n",
    "    y_pred = forward(6)\n",
    "\n",
    "    # log\n",
    "    print(f\"epoch: {i+1:>2} -> f(6)={y_pred:>7.3f} | loss={l:>9.5f} | w_old= {w + lr * dw:.3f} | step= {lr * dw:.5f} | w_new= {w:.3f}\")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Implementation 2\n",
    "<ul>\n",
    "    <li style=\"font-family: consolas;\">prediction : <span style=\"color: red\">Manual</span></li>\n",
    "    <li style=\"font-family: consolas;\">gradient &nbsp;&nbsp;: <span style=\"color: cyan\">torch</span></li>\n",
    "    <li style=\"font-family: consolas;\">loss &nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;: <span style=\"color: red\">Manual</span></li>\n",
    "    <li style=\"font-family: consolas;\">update &nbsp;&nbsp;&nbsp;&nbsp;: <span style=\"color: red\">Manual</span></li>\n",
    "</ul>"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 26,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "epoch:  1 -> f(6)=  2.640 | loss= 44.00000 | w_old= 0.000 | step= -0.44000 | w_new= 0.440\n",
      "epoch:  2 -> f(6)=  4.699 | loss= 26.76960 | w_old= 0.440 | step= -0.34320 | w_new= 0.783\n",
      "epoch:  3 -> f(6)=  6.305 | loss= 16.28662 | w_old= 0.783 | step= -0.26770 | w_new= 1.051\n",
      "epoch:  4 -> f(6)=  7.558 | loss=  9.90878 | w_old= 1.051 | step= -0.20880 | w_new= 1.260\n",
      "epoch:  5 -> f(6)=  8.535 | loss=  6.02850 | w_old= 1.260 | step= -0.16287 | w_new= 1.423\n",
      "epoch:  6 -> f(6)=  9.298 | loss=  3.66774 | w_old= 1.423 | step= -0.12704 | w_new= 1.550\n",
      "epoch:  7 -> f(6)=  9.892 | loss=  2.23145 | w_old= 1.550 | step= -0.09909 | w_new= 1.649\n",
      "epoch:  8 -> f(6)= 10.356 | loss=  1.35762 | w_old= 1.649 | step= -0.07729 | w_new= 1.726\n",
      "epoch:  9 -> f(6)= 10.718 | loss=  0.82597 | w_old= 1.726 | step= -0.06029 | w_new= 1.786\n",
      "epoch: 10 -> f(6)= 11.000 | loss=  0.50252 | w_old= 1.786 | step= -0.04702 | w_new= 1.833\n",
      "epoch: 11 -> f(6)= 11.220 | loss=  0.30573 | w_old= 1.833 | step= -0.03668 | w_new= 1.870\n",
      "epoch: 12 -> f(6)= 11.391 | loss=  0.18601 | w_old= 1.870 | step= -0.02861 | w_new= 1.899\n",
      "epoch: 13 -> f(6)= 11.525 | loss=  0.11317 | w_old= 1.899 | step= -0.02231 | w_new= 1.921\n",
      "epoch: 14 -> f(6)= 11.630 | loss=  0.06885 | w_old= 1.921 | step= -0.01741 | w_new= 1.938\n",
      "epoch: 15 -> f(6)= 11.711 | loss=  0.04189 | w_old= 1.938 | step= -0.01358 | w_new= 1.952\n",
      "epoch: 16 -> f(6)= 11.775 | loss=  0.02549 | w_old= 1.952 | step= -0.01059 | w_new= 1.962\n",
      "epoch: 17 -> f(6)= 11.824 | loss=  0.01551 | w_old= 1.962 | step= -0.00826 | w_new= 1.971\n",
      "epoch: 18 -> f(6)= 11.863 | loss=  0.00943 | w_old= 1.971 | step= -0.00644 | w_new= 1.977\n",
      "epoch: 19 -> f(6)= 11.893 | loss=  0.00574 | w_old= 1.977 | step= -0.00503 | w_new= 1.982\n",
      "epoch: 20 -> f(6)= 11.917 | loss=  0.00349 | w_old= 1.982 | step= -0.00392 | w_new= 1.986\n"
     ]
    }
   ],
   "source": [
    "# f(x) = 2x\n",
    "train_x = torch.tensor([1, 2, 3, 4, 5] , dtype= torch.float32)\n",
    "train_y = torch.tensor([2, 4, 6, 8, 10], dtype= torch.float32)\n",
    "\n",
    "# initial weight\n",
    "w = torch.tensor(0.0, dtype= torch.float32, requires_grad= True)\n",
    "\n",
    "# feed-forward\n",
    "def forward(x):\n",
    "    return w * x\n",
    "\n",
    "# MSE loss\n",
    "def loss(y_pred, train_y):\n",
    "    return ((y_pred - train_y) ** 2).mean()\n",
    "\n",
    "# hyper parameters\n",
    "lr = 0.01\n",
    "epoch = 20\n",
    "\n",
    "for i in range(epoch):\n",
    "\n",
    "    # forward\n",
    "    y_pred = forward(train_x)\n",
    "\n",
    "    # backward\n",
    "    l = loss(train_y, y_pred)\n",
    "    l.backward()\n",
    "    \n",
    "    # update parameters\n",
    "    with torch.no_grad():\n",
    "        w -= lr * w.grad\n",
    "\n",
    "    # test\n",
    "    y_pred = forward(6)\n",
    "\n",
    "    # log\n",
    "    print(f\"epoch: {i+1:>2} -> f(6)={y_pred:>7.3f} | loss={l:>9.5f} | w_old= {w + lr * w.grad:.3f} | step= {lr * w.grad:.5f} | w_new= {w:.3f}\")\n",
    "\n",
    "    # remove previous gradients\n",
    "    w.grad.zero_()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Implementation 3\n",
    "<ul>\n",
    "    <li style=\"font-family: consolas;\">prediction : <span style=\"color: red\">Manual</span></li>\n",
    "    <li style=\"font-family: consolas;\">gradient &nbsp;&nbsp;: <span style=\"color: cyan\">Auto</span></li>\n",
    "    <li style=\"font-family: consolas;\">loss &nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;: <span style=\"color: cyan\">Auto</span></li>\n",
    "    <li style=\"font-family: consolas;\">update &nbsp;&nbsp;&nbsp;&nbsp;: <span style=\"color: cyan\">Auto</span></li>\n",
    "</ul>"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 27,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "epoch:  1 -> f(6)=  2.640 | loss= 44.00000 | w_old= 0.000 | step= -0.44000 | w_new= 0.440\n",
      "epoch:  2 -> f(6)=  4.699 | loss= 26.76960 | w_old= 0.440 | step= -0.34320 | w_new= 0.783\n",
      "epoch:  3 -> f(6)=  6.305 | loss= 16.28662 | w_old= 0.783 | step= -0.26770 | w_new= 1.051\n",
      "epoch:  4 -> f(6)=  7.558 | loss=  9.90878 | w_old= 1.051 | step= -0.20880 | w_new= 1.260\n",
      "epoch:  5 -> f(6)=  8.535 | loss=  6.02850 | w_old= 1.260 | step= -0.16287 | w_new= 1.423\n",
      "epoch:  6 -> f(6)=  9.298 | loss=  3.66774 | w_old= 1.423 | step= -0.12704 | w_new= 1.550\n",
      "epoch:  7 -> f(6)=  9.892 | loss=  2.23145 | w_old= 1.550 | step= -0.09909 | w_new= 1.649\n",
      "epoch:  8 -> f(6)= 10.356 | loss=  1.35762 | w_old= 1.649 | step= -0.07729 | w_new= 1.726\n",
      "epoch:  9 -> f(6)= 10.718 | loss=  0.82597 | w_old= 1.726 | step= -0.06029 | w_new= 1.786\n",
      "epoch: 10 -> f(6)= 11.000 | loss=  0.50252 | w_old= 1.786 | step= -0.04702 | w_new= 1.833\n",
      "epoch: 11 -> f(6)= 11.220 | loss=  0.30573 | w_old= 1.833 | step= -0.03668 | w_new= 1.870\n",
      "epoch: 12 -> f(6)= 11.391 | loss=  0.18601 | w_old= 1.870 | step= -0.02861 | w_new= 1.899\n",
      "epoch: 13 -> f(6)= 11.525 | loss=  0.11317 | w_old= 1.899 | step= -0.02231 | w_new= 1.921\n",
      "epoch: 14 -> f(6)= 11.630 | loss=  0.06885 | w_old= 1.921 | step= -0.01741 | w_new= 1.938\n",
      "epoch: 15 -> f(6)= 11.711 | loss=  0.04189 | w_old= 1.938 | step= -0.01358 | w_new= 1.952\n",
      "epoch: 16 -> f(6)= 11.775 | loss=  0.02549 | w_old= 1.952 | step= -0.01059 | w_new= 1.962\n",
      "epoch: 17 -> f(6)= 11.824 | loss=  0.01551 | w_old= 1.962 | step= -0.00826 | w_new= 1.971\n",
      "epoch: 18 -> f(6)= 11.863 | loss=  0.00943 | w_old= 1.971 | step= -0.00644 | w_new= 1.977\n",
      "epoch: 19 -> f(6)= 11.893 | loss=  0.00574 | w_old= 1.977 | step= -0.00503 | w_new= 1.982\n",
      "epoch: 20 -> f(6)= 11.917 | loss=  0.00349 | w_old= 1.982 | step= -0.00392 | w_new= 1.986\n"
     ]
    }
   ],
   "source": [
    "# f(x) = 2x\n",
    "train_x = torch.tensor([1, 2, 3, 4, 5] , dtype= torch.float32)\n",
    "train_y = torch.tensor([2, 4, 6, 8, 10], dtype= torch.float32)\n",
    "\n",
    "# initial weight\n",
    "w = torch.tensor(0.0, dtype= torch.float32, requires_grad= True)\n",
    "\n",
    "# feed-forward\n",
    "def forward(x):\n",
    "    return w * x\n",
    "\n",
    "# hyper parameters\n",
    "lr = 0.01\n",
    "epoch = 20\n",
    "loss = MSELoss()\n",
    "optimizer = SGD([w], lr)\n",
    "\n",
    "for i in range(epoch):\n",
    "\n",
    "    # forward\n",
    "    y_pred = forward(train_x)\n",
    "\n",
    "    # backward\n",
    "    l = loss(y_pred, train_y)\n",
    "    l.backward()\n",
    "\n",
    "    # update parameters\n",
    "    optimizer.step()\n",
    "\n",
    "    # test\n",
    "    y_pred = forward(6)\n",
    "\n",
    "    # log\n",
    "    print(f\"epoch: {i+1:>2} -> f(6)={y_pred:>7.3f} | loss={l:>9.5f} | w_old= {w + lr * w.grad:.3f} | step= {lr * w.grad:.5f} | w_new= {w:.3f}\")\n",
    "    \n",
    "    # remove previous gradients\n",
    "    optimizer.zero_grad()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Implementation 4\n",
    "<ul>\n",
    "    <li style=\"font-family: consolas;\">prediction : <span style=\"color: cyan\">torch</span></li>\n",
    "    <li style=\"font-family: consolas;\">gradient &nbsp;&nbsp;: <span style=\"color: cyan\">torch</span></li>\n",
    "    <li style=\"font-family: consolas;\">loss &nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;: <span style=\"color: cyan\">torch</span></li>\n",
    "    <li style=\"font-family: consolas;\">update &nbsp;&nbsp;&nbsp;&nbsp;: <span style=\"color: cyan\">torch</span></li>\n",
    "</ul>"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 28,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "epoch:  1 -> f(6)=  2.640 | loss= 44.00000 | w_old= -0.000 | step= -0.44000 | w_new= 0.440\n",
      "epoch:  2 -> f(6)=  4.699 | loss= 26.76960 | w_old=  0.440 | step= -0.34320 | w_new= 0.783\n",
      "epoch:  3 -> f(6)=  6.305 | loss= 16.28662 | w_old=  0.783 | step= -0.26770 | w_new= 1.051\n",
      "epoch:  4 -> f(6)=  7.558 | loss=  9.90878 | w_old=  1.051 | step= -0.20880 | w_new= 1.260\n",
      "epoch:  5 -> f(6)=  8.535 | loss=  6.02850 | w_old=  1.260 | step= -0.16287 | w_new= 1.423\n",
      "epoch:  6 -> f(6)=  9.298 | loss=  3.66774 | w_old=  1.423 | step= -0.12704 | w_new= 1.550\n",
      "epoch:  7 -> f(6)=  9.892 | loss=  2.23145 | w_old=  1.550 | step= -0.09909 | w_new= 1.649\n",
      "epoch:  8 -> f(6)= 10.356 | loss=  1.35762 | w_old=  1.649 | step= -0.07729 | w_new= 1.726\n",
      "epoch:  9 -> f(6)= 10.718 | loss=  0.82597 | w_old=  1.726 | step= -0.06029 | w_new= 1.786\n",
      "epoch: 10 -> f(6)= 11.000 | loss=  0.50252 | w_old=  1.786 | step= -0.04702 | w_new= 1.833\n",
      "epoch: 11 -> f(6)= 11.220 | loss=  0.30573 | w_old=  1.833 | step= -0.03668 | w_new= 1.870\n",
      "epoch: 12 -> f(6)= 11.391 | loss=  0.18601 | w_old=  1.870 | step= -0.02861 | w_new= 1.899\n",
      "epoch: 13 -> f(6)= 11.525 | loss=  0.11317 | w_old=  1.899 | step= -0.02231 | w_new= 1.921\n",
      "epoch: 14 -> f(6)= 11.630 | loss=  0.06885 | w_old=  1.921 | step= -0.01741 | w_new= 1.938\n",
      "epoch: 15 -> f(6)= 11.711 | loss=  0.04189 | w_old=  1.938 | step= -0.01358 | w_new= 1.952\n",
      "epoch: 16 -> f(6)= 11.775 | loss=  0.02549 | w_old=  1.952 | step= -0.01059 | w_new= 1.962\n",
      "epoch: 17 -> f(6)= 11.824 | loss=  0.01551 | w_old=  1.962 | step= -0.00826 | w_new= 1.971\n",
      "epoch: 18 -> f(6)= 11.863 | loss=  0.00943 | w_old=  1.971 | step= -0.00644 | w_new= 1.977\n",
      "epoch: 19 -> f(6)= 11.893 | loss=  0.00574 | w_old=  1.977 | step= -0.00503 | w_new= 1.982\n",
      "epoch: 20 -> f(6)= 11.917 | loss=  0.00349 | w_old=  1.982 | step= -0.00392 | w_new= 1.986\n"
     ]
    }
   ],
   "source": [
    "# f(x) = 2x\n",
    "\n",
    "# row: num of samples - column: num of features\n",
    "train_x = torch.tensor([[1], [2], [3], [4], [5]] , dtype= torch.float32)\n",
    "train_y = torch.tensor([[2], [4], [6], [8], [10]], dtype= torch.float32)\n",
    "\n",
    "model = Linear(train_x.shape[1], train_y.shape[1], bias= False)\n",
    "\n",
    "# initial weight\n",
    "with torch.no_grad():\n",
    "    model.weight.fill_(0.0)\n",
    "\n",
    "# hyper parameters\n",
    "lr = 0.01\n",
    "epoch = 20\n",
    "loss = MSELoss()\n",
    "optimizer = SGD(model.parameters(), lr)\n",
    "\n",
    "for i in range(epoch):\n",
    "\n",
    "    # forward\n",
    "    y_pred = model(train_x)\n",
    "\n",
    "    # backward\n",
    "    l = loss(y_pred, train_y)\n",
    "    l.backward()\n",
    "\n",
    "    # update parameters\n",
    "    optimizer.step()\n",
    "\n",
    "    # test\n",
    "    y_pred = model(torch.tensor([[6]], dtype= torch.float32))\n",
    "\n",
    "    # log\n",
    "    print(f\"epoch: {i+1:>2} -> f(6)={y_pred.item():>7.3f} | loss={l:>9.5f} | w_old= {model.weight.item() + lr * model.weight.grad.item():>6.3f} | step= {lr * model.weight.grad.item():.5f} | w_new= {model.weight.item():.3f}\")\n",
    "\n",
    "    # remove previous gradients\n",
    "    optimizer.zero_grad()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Implementation 5 [with custom model]\n",
    "<ul>\n",
    "    <li style=\"font-family: consolas;\">prediction : <span style=\"color: cyan\">torch</span></li>\n",
    "    <li style=\"font-family: consolas;\">gradient &nbsp;&nbsp;: <span style=\"color: cyan\">torch</span></li>\n",
    "    <li style=\"font-family: consolas;\">loss &nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;: <span style=\"color: cyan\">torch</span></li>\n",
    "    <li style=\"font-family: consolas;\">update &nbsp;&nbsp;&nbsp;&nbsp;: <span style=\"color: cyan\">torch</span></li>\n",
    "</ul>"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 29,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "epoch:  1 -> f(6)=  2.640 | loss= 44.00000 | w_old= -0.000 | step= -0.44000 | w_new= 0.440\n",
      "epoch:  2 -> f(6)=  4.699 | loss= 26.76960 | w_old=  0.440 | step= -0.34320 | w_new= 0.783\n",
      "epoch:  3 -> f(6)=  6.305 | loss= 16.28662 | w_old=  0.783 | step= -0.26770 | w_new= 1.051\n",
      "epoch:  4 -> f(6)=  7.558 | loss=  9.90878 | w_old=  1.051 | step= -0.20880 | w_new= 1.260\n",
      "epoch:  5 -> f(6)=  8.535 | loss=  6.02850 | w_old=  1.260 | step= -0.16287 | w_new= 1.423\n",
      "epoch:  6 -> f(6)=  9.298 | loss=  3.66774 | w_old=  1.423 | step= -0.12704 | w_new= 1.550\n",
      "epoch:  7 -> f(6)=  9.892 | loss=  2.23145 | w_old=  1.550 | step= -0.09909 | w_new= 1.649\n",
      "epoch:  8 -> f(6)= 10.356 | loss=  1.35762 | w_old=  1.649 | step= -0.07729 | w_new= 1.726\n",
      "epoch:  9 -> f(6)= 10.718 | loss=  0.82597 | w_old=  1.726 | step= -0.06029 | w_new= 1.786\n",
      "epoch: 10 -> f(6)= 11.000 | loss=  0.50252 | w_old=  1.786 | step= -0.04702 | w_new= 1.833\n",
      "epoch: 11 -> f(6)= 11.220 | loss=  0.30573 | w_old=  1.833 | step= -0.03668 | w_new= 1.870\n",
      "epoch: 12 -> f(6)= 11.391 | loss=  0.18601 | w_old=  1.870 | step= -0.02861 | w_new= 1.899\n",
      "epoch: 13 -> f(6)= 11.525 | loss=  0.11317 | w_old=  1.899 | step= -0.02231 | w_new= 1.921\n",
      "epoch: 14 -> f(6)= 11.630 | loss=  0.06885 | w_old=  1.921 | step= -0.01741 | w_new= 1.938\n",
      "epoch: 15 -> f(6)= 11.711 | loss=  0.04189 | w_old=  1.938 | step= -0.01358 | w_new= 1.952\n",
      "epoch: 16 -> f(6)= 11.775 | loss=  0.02549 | w_old=  1.952 | step= -0.01059 | w_new= 1.962\n",
      "epoch: 17 -> f(6)= 11.824 | loss=  0.01551 | w_old=  1.962 | step= -0.00826 | w_new= 1.971\n",
      "epoch: 18 -> f(6)= 11.863 | loss=  0.00943 | w_old=  1.971 | step= -0.00644 | w_new= 1.977\n",
      "epoch: 19 -> f(6)= 11.893 | loss=  0.00574 | w_old=  1.977 | step= -0.00503 | w_new= 1.982\n",
      "epoch: 20 -> f(6)= 11.917 | loss=  0.00349 | w_old=  1.982 | step= -0.00392 | w_new= 1.986\n"
     ]
    }
   ],
   "source": [
    "# f(x) = 2x\n",
    "\n",
    "# row: num of samples - column: num of features\n",
    "train_x = torch.tensor([[1], [2], [3], [4], [5]] , dtype= torch.float32)\n",
    "train_y = torch.tensor([[2], [4], [6], [8], [10]], dtype= torch.float32)\n",
    "\n",
    "# custom model\n",
    "class LinearRegression(torch.nn.Module):\n",
    "    def __init__(self, input_dim, output_dim):\n",
    "        super(LinearRegression, self).__init__()\n",
    "\n",
    "        self.regressor = Linear(input_dim, output_dim, bias= False)\n",
    "        \n",
    "        # initial weight\n",
    "        with torch.no_grad():\n",
    "            self.regressor.weight.fill_(0.0)\n",
    "    \n",
    "    def forward(self, x):\n",
    "        return self.regressor(x)\n",
    "\n",
    "model = LinearRegression(train_x.shape[1], train_y.shape[1])\n",
    "\n",
    "# hyper parameters\n",
    "lr = 0.01\n",
    "epoch = 20\n",
    "loss = MSELoss()\n",
    "optimizer = SGD(model.parameters(), lr)\n",
    "\n",
    "for i in range(epoch):\n",
    "\n",
    "    # forward\n",
    "    y_pred = model(train_x)\n",
    "\n",
    "    # backward\n",
    "    l = loss(y_pred, train_y)\n",
    "    l.backward()\n",
    "\n",
    "    # update parameters\n",
    "    optimizer.step()\n",
    "\n",
    "    # test\n",
    "    y_pred = model(torch.tensor([[6]], dtype= torch.float32))\n",
    "    \n",
    "    # log\n",
    "    print(f\"epoch: {i+1:>2} -> f(6)={y_pred.item():>7.3f} | loss={l:>9.5f} | w_old= {model.regressor.weight.item() + lr * model.regressor.weight.grad.item():>6.3f} | step= {lr * model.regressor.weight.grad.item():.5f} | w_new= {model.regressor.weight.item():.3f}\")\n",
    "    \n",
    "    # remove previous gradients\n",
    "    optimizer.zero_grad()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Plot"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 30,
   "metadata": {},
   "outputs": [],
   "source": [
    "# generate artificial data\n",
    "n_samples, n_features = [100, 1]\n",
    "x, y = datasets.make_regression(n_samples, n_features, noise= 5, random_state= 42)\n",
    "\n",
    "# convert numpy.ndarray to torch.Tensor\n",
    "train_x = torch.from_numpy(x.astype(np.float32))\n",
    "train_y = torch.from_numpy(y.astype(np.float32)).view(-1, 1)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 31,
   "metadata": {},
   "outputs": [],
   "source": [
    "# custom model\n",
    "class LinearRegression(torch.nn.Module):\n",
    "    def __init__(self, input_dim, output_dim) -> None:\n",
    "        super(LinearRegression, self).__init__()\n",
    "\n",
    "        self.node = torch.nn.Linear(input_dim, output_dim, bias= False)\n",
    "    \n",
    "    def forward(self, x):\n",
    "        return self.node(x)\n",
    "    \n",
    "model = LinearRegression(n_features, 1)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 32,
   "metadata": {},
   "outputs": [],
   "source": [
    "# plot stuff\n",
    "W = torch.linspace(-100, 100, 500)\n",
    "L = torch.zeros(size= (500, ))\n",
    "\n",
    "for i, val in enumerate(W):\n",
    "    with torch.no_grad():\n",
    "        model.node.weight.fill_(val)\n",
    "        L[i] = loss(model(train_x), train_y)\n",
    "\n",
    "state = []"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 33,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "epoch:  0 -> loss: 3847.11401\n",
      "epoch:  1 -> loss: 3240.04541\n",
      "epoch:  2 -> loss: 2729.26758\n",
      "epoch:  3 -> loss: 2299.50806\n",
      "epoch:  4 -> loss: 1937.91528\n",
      "epoch:  5 -> loss: 1633.67761\n",
      "epoch:  6 -> loss: 1377.69702\n",
      "epoch:  7 -> loss: 1162.31921\n",
      "epoch:  8 -> loss:  981.10413\n",
      "epoch:  9 -> loss:  828.63281\n",
      "epoch: 10 -> loss:  700.34589\n",
      "epoch: 11 -> loss:  592.40747\n",
      "epoch: 12 -> loss:  501.58997\n",
      "epoch: 13 -> loss:  425.17764\n",
      "epoch: 14 -> loss:  360.88556\n",
      "epoch: 15 -> loss:  306.79138\n",
      "epoch: 16 -> loss:  261.27737\n",
      "epoch: 17 -> loss:  222.98265\n",
      "epoch: 18 -> loss:  190.76219\n",
      "epoch: 19 -> loss:  163.65236\n",
      "epoch: 20 -> loss:  140.84265\n"
     ]
    }
   ],
   "source": [
    "# initial weight\n",
    "with torch.no_grad():\n",
    "    model.node.weight.fill_(-25)\n",
    "\n",
    "# hyper parameters\n",
    "epoch = 21\n",
    "lr = 0.05\n",
    "optimizer = torch.optim.SGD(model.parameters(), lr= lr)\n",
    "loss = torch.nn.MSELoss()\n",
    "\n",
    "for i in range(epoch):\n",
    "\n",
    "    # forward\n",
    "    y_pred = model(train_x)\n",
    "\n",
    "    # backward\n",
    "    l = loss(y_pred, train_y)\n",
    "    l.backward()\n",
    "\n",
    "    # save new y_pred every 5 epochs\n",
    "    if i % 5 == 0:\n",
    "        state.append([i, model.node.weight.item(), l.item(), y_pred.detach().numpy()])\n",
    "\n",
    "    # update parameters\n",
    "    optimizer.step()\n",
    "    optimizer.zero_grad()\n",
    "\n",
    "    # log\n",
    "    print(f\"epoch: {i:>2} -> loss: {l.item():>10.5f}\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# plot\n",
    "rows = epoch // 5 + 1\n",
    "fig, axs = plt.subplots(nrows= rows, ncols= 2, figsize= (10, 20), layout= 'compressed')\n",
    "\n",
    "for row in range(rows):\n",
    "    axs[row, 0].plot(train_x, train_y, 'ro')\n",
    "    axs[row, 0].plot(train_x, state[row][3], 'b')\n",
    "    axs[row, 0].set_title(f\"epoch: {state[row][0]}\")\n",
    "    axs[row, 1].plot(state[row][1], state[row][2], 'ro')\n",
    "    axs[row, 1].plot(W, L, 'b')\n",
    "    axs[row, 1].set_title(\"loss function\")\n",
    "\n",
    "plt.show()"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.12.2"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
